{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelnath/.virtualenvs/224n_final_proj/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import requests\n",
    "import ciso8601\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Python-all-4b2efe4a27feed92\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"codeparrot/github-code\", streaming=True, split='train', languages=[\"Python\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_set(code_entry) -> dict[str:int]:\n",
    "    features = dict();\n",
    "    user_repo_name = code_entry['repo_name'].split('/')\n",
    "    owner = user_repo_name[0]\n",
    "    repo = \"\".join(user_repo_name[1:])\n",
    "    repo_response = requests.get(f\"https://api.github.com/repos/{owner}/{repo}\")\n",
    "    content = json.loads(repo_response.text)\n",
    "    features[\"num_stars\"] = content.get(\"stargazers_count\", 0)\n",
    "    features[\"num_forks\"] = content.get(\"forks_count\", 0)\n",
    "    features[\"num_watchers\"] = content.get(\"watchers_count\", 0)\n",
    "    features[\"num_open_issues\"] = content.get(\"open_issues_count\", 0)\n",
    "    parsed_datetime = ciso8601.parse_datetime(content.get(\"created_at\", datetime.now().isoformat()))\n",
    "    timestamp = time.mktime(parsed_datetime.timetuple())\n",
    "    features[\"created_at\"] = timestamp\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE BELOW IS FOR PYTHON FILES (LEVERAGES INDENTATION RULES)\n",
    "def construct_list_of_functions(code_entry) -> list[str]:\n",
    "    raw_code = code_entry[\"code\"]\n",
    "    lines = raw_code.split('\\n')\n",
    "    start = -1\n",
    "    functions = []\n",
    "    amnt_tabs = 0\n",
    "    for i in range(len(lines)):\n",
    "        # disregard empty lines (prune trailing whitespace later)\n",
    "        if (start != -1 and len(lines[i]) > 0):\n",
    "            amnt_tabs_new = len(lines[i].rstrip()) - len(lines[i].strip())\n",
    "            if amnt_tabs_new <= amnt_tabs:\n",
    "                functions.append((\"\\n\".join(lines[start:i])).strip())\n",
    "                start = -1\n",
    "        elif lines[i].lstrip().startswith(\"def \"):\n",
    "            start = i\n",
    "            amnt_tabs = len(lines[i].rstrip()) - len(lines[i].strip())\n",
    "    return functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "MAX_AMNT_CODE_ENTRIES = 1\n",
    "augmented_code_entry_data = []\n",
    "for i in range(MAX_AMNT_CODE_ENTRIES):\n",
    "    code_entry = next(iterable_ds)\n",
    "    features_set = construct_feature_set(code_entry)\n",
    "    functions = construct_list_of_functions(code_entry)\n",
    "    data = dict()\n",
    "    # data[\"features\"] = []\n",
    "    # data[\"snippets\"] = []\n",
    "    augmented_code_entry_data.append(data)\n",
    "print(augmented_code_entry_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_code_entry(entry):\n",
    "    repo_features = construct_feature_set(entry)\n",
    "    entry[\"reputation_features\"] = repo_features\n",
    "    if entry[\"language\"] != \"Python\":\n",
    "        return entry\n",
    "    entry[\"functions\"] = construct_list_of_functions(entry)\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = ds.map(augment_code_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'code': 'from django import forms\\nfrom django.core.exceptions import ValidationError\\nfrom django.core.validators import validate_slug\\nfrom django.db import models\\nfrom django.utils import simplejson as json\\nfrom django.utils.text import capfirst\\nfrom django.utils.translation import ugettext_lazy as _\\n\\nfrom philo.forms.fields import JSONFormField\\nfrom philo.utils.registry import RegistryIterator\\nfrom philo.validators import TemplateValidator, json_validator\\n#from philo.models.fields.entities import *\\n\\n\\nclass TemplateField(models.TextField):\\n\\t\"\"\"A :class:`TextField` which is validated with a :class:`.TemplateValidator`. ``allow``, ``disallow``, and ``secure`` will be passed into the validator\\'s construction.\"\"\"\\n\\tdef __init__(self, allow=None, disallow=None, secure=True, *args, **kwargs):\\n\\t\\tsuper(TemplateField, self).__init__(*args, **kwargs)\\n\\t\\tself.validators.append(TemplateValidator(allow, disallow, secure))\\n\\n\\nclass JSONDescriptor(object):\\n\\tdef __init__(self, field):\\n\\t\\tself.field = field\\n\\t\\n\\tdef __get__(self, instance, owner):\\n\\t\\tif instance is None:\\n\\t\\t\\traise AttributeError # ?\\n\\t\\t\\n\\t\\tif self.field.name not in instance.__dict__:\\n\\t\\t\\tjson_string = getattr(instance, self.field.attname)\\n\\t\\t\\tinstance.__dict__[self.field.name] = json.loads(json_string)\\n\\t\\t\\n\\t\\treturn instance.__dict__[self.field.name]\\n\\t\\n\\tdef __set__(self, instance, value):\\n\\t\\tinstance.__dict__[self.field.name] = value\\n\\t\\tsetattr(instance, self.field.attname, json.dumps(value))\\n\\t\\n\\tdef __delete__(self, instance):\\n\\t\\tdel(instance.__dict__[self.field.name])\\n\\t\\tsetattr(instance, self.field.attname, json.dumps(None))\\n\\n\\nclass JSONField(models.TextField):\\n\\t\"\"\"A :class:`TextField` which stores its value on the model instance as a python object and stores its value in the database as JSON. Validated with :func:`.json_validator`.\"\"\"\\n\\tdefault_validators = [json_validator]\\n\\t\\n\\tdef get_attname(self):\\n\\t\\treturn \"%s_json\" % self.name\\n\\t\\n\\tdef contribute_to_class(self, cls, name):\\n\\t\\tsuper(JSONField, self).contribute_to_class(cls, name)\\n\\t\\tsetattr(cls, name, JSONDescriptor(self))\\n\\t\\tmodels.signals.pre_init.connect(self.fix_init_kwarg, sender=cls)\\n\\t\\n\\tdef fix_init_kwarg(self, sender, args, kwargs, **signal_kwargs):\\n\\t\\t# Anything passed in as self.name is assumed to come from a serializer and\\n\\t\\t# will be treated as a json string.\\n\\t\\tif self.name in kwargs:\\n\\t\\t\\tvalue = kwargs.pop(self.name)\\n\\t\\t\\t\\n\\t\\t\\t# Hack to handle the xml serializer\\'s handling of \"null\"\\n\\t\\t\\tif value is None:\\n\\t\\t\\t\\tvalue = \\'null\\'\\n\\t\\t\\t\\n\\t\\t\\tkwargs[self.attname] = value\\n\\t\\n\\tdef formfield(self, *args, **kwargs):\\n\\t\\tkwargs[\"form_class\"] = JSONFormField\\n\\t\\treturn super(JSONField, self).formfield(*args, **kwargs)\\n\\n\\nclass SlugMultipleChoiceField(models.Field):\\n\\t\"\"\"Stores a selection of multiple items with unique slugs in the form of a comma-separated list. Also knows how to correctly handle :class:`RegistryIterator`\\\\ s passed in as choices.\"\"\"\\n\\t__metaclass__ = models.SubfieldBase\\n\\tdescription = _(\"Comma-separated slug field\")\\n\\t\\n\\tdef get_internal_type(self):\\n\\t\\treturn \"TextField\"\\n\\t\\n\\tdef to_python(self, value):\\n\\t\\tif not value:\\n\\t\\t\\treturn []\\n\\t\\t\\n\\t\\tif isinstance(value, list):\\n\\t\\t\\treturn value\\n\\t\\t\\n\\t\\treturn value.split(\\',\\')\\n\\t\\n\\tdef get_prep_value(self, value):\\n\\t\\treturn \\',\\'.join(value)\\n\\t\\n\\tdef formfield(self, **kwargs):\\n\\t\\t# This is necessary because django hard-codes TypedChoiceField for things with choices.\\n\\t\\tdefaults = {\\n\\t\\t\\t\\'widget\\': forms.CheckboxSelectMultiple,\\n\\t\\t\\t\\'choices\\': self.get_choices(include_blank=False),\\n\\t\\t\\t\\'label\\': capfirst(self.verbose_name),\\n\\t\\t\\t\\'required\\': not self.blank,\\n\\t\\t\\t\\'help_text\\': self.help_text\\n\\t\\t}\\n\\t\\tif self.has_default():\\n\\t\\t\\tif callable(self.default):\\n\\t\\t\\t\\tdefaults[\\'initial\\'] = self.default\\n\\t\\t\\t\\tdefaults[\\'show_hidden_initial\\'] = True\\n\\t\\t\\telse:\\n\\t\\t\\t\\tdefaults[\\'initial\\'] = self.get_default()\\n\\t\\t\\n\\t\\tfor k in kwargs.keys():\\n\\t\\t\\tif k not in (\\'coerce\\', \\'empty_value\\', \\'choices\\', \\'required\\',\\n\\t\\t\\t\\t\\t\\t \\'widget\\', \\'label\\', \\'initial\\', \\'help_text\\',\\n\\t\\t\\t\\t\\t\\t \\'error_messages\\', \\'show_hidden_initial\\'):\\n\\t\\t\\t\\tdel kwargs[k]\\n\\t\\t\\n\\t\\tdefaults.update(kwargs)\\n\\t\\tform_class = forms.TypedMultipleChoiceField\\n\\t\\treturn form_class(**defaults)\\n\\t\\n\\tdef validate(self, value, model_instance):\\n\\t\\tinvalid_values = []\\n\\t\\tfor val in value:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tvalidate_slug(val)\\n\\t\\t\\texcept ValidationError:\\n\\t\\t\\t\\tinvalid_values.append(val)\\n\\t\\t\\n\\t\\tif invalid_values:\\n\\t\\t\\t# should really make a custom message.\\n\\t\\t\\traise ValidationError(self.error_messages[\\'invalid_choice\\'] % invalid_values)\\n\\t\\n\\tdef _get_choices(self):\\n\\t\\tif isinstance(self._choices, RegistryIterator):\\n\\t\\t\\treturn self._choices.copy()\\n\\t\\telif hasattr(self._choices, \\'next\\'):\\n\\t\\t\\tchoices, self._choices = itertools.tee(self._choices)\\n\\t\\t\\treturn choices\\n\\t\\telse:\\n\\t\\t\\treturn self._choices\\n\\tchoices = property(_get_choices)\\n\\n\\ntry:\\n\\tfrom south.modelsinspector import add_introspection_rules\\nexcept ImportError:\\n\\tpass\\nelse:\\n\\tadd_introspection_rules([], [\"^philo\\\\.models\\\\.fields\\\\.SlugMultipleChoiceField\"])\\n\\tadd_introspection_rules([], [\"^philo\\\\.models\\\\.fields\\\\.TemplateField\"])\\n\\tadd_introspection_rules([], [\"^philo\\\\.models\\\\.fields\\\\.JSONField\"])', 'repo_name': 'ithinksw/philo', 'path': 'philo/models/fields/__init__.py', 'language': 'Python', 'license': 'isc', 'size': 4971, 'reputation_features': {'num_stars': 50, 'num_forks': 12, 'num_watchers': 50, 'num_open_issues': 3, 'created_at': 1274352479.0}, 'functions': ['def __init__(self, allow=None, disallow=None, secure=True, *args, **kwargs):\\n\\t\\tsuper(TemplateField, self).__init__(*args, **kwargs)\\n\\t\\tself.validators.append(TemplateValidator(allow, disallow, secure))', 'def __init__(self, field):\\n\\t\\tself.field = field', 'def __get__(self, instance, owner):\\n\\t\\tif instance is None:\\n\\t\\t\\traise AttributeError # ?', 'def __set__(self, instance, value):\\n\\t\\tinstance.__dict__[self.field.name] = value\\n\\t\\tsetattr(instance, self.field.attname, json.dumps(value))', 'def __delete__(self, instance):\\n\\t\\tdel(instance.__dict__[self.field.name])\\n\\t\\tsetattr(instance, self.field.attname, json.dumps(None))', 'def get_attname(self):\\n\\t\\treturn \"%s_json\" % self.name', 'def contribute_to_class(self, cls, name):\\n\\t\\tsuper(JSONField, self).contribute_to_class(cls, name)\\n\\t\\tsetattr(cls, name, JSONDescriptor(self))\\n\\t\\tmodels.signals.pre_init.connect(self.fix_init_kwarg, sender=cls)', 'def fix_init_kwarg(self, sender, args, kwargs, **signal_kwargs):\\n\\t\\t# Anything passed in as self.name is assumed to come from a serializer and\\n\\t\\t# will be treated as a json string.\\n\\t\\tif self.name in kwargs:\\n\\t\\t\\tvalue = kwargs.pop(self.name)', 'def formfield(self, *args, **kwargs):\\n\\t\\tkwargs[\"form_class\"] = JSONFormField\\n\\t\\treturn super(JSONField, self).formfield(*args, **kwargs)', 'def get_internal_type(self):\\n\\t\\treturn \"TextField\"', 'def to_python(self, value):\\n\\t\\tif not value:\\n\\t\\t\\treturn []', \"def get_prep_value(self, value):\\n\\t\\treturn ','.join(value)\", \"def formfield(self, **kwargs):\\n\\t\\t# This is necessary because django hard-codes TypedChoiceField for things with choices.\\n\\t\\tdefaults = {\\n\\t\\t\\t'widget': forms.CheckboxSelectMultiple,\\n\\t\\t\\t'choices': self.get_choices(include_blank=False),\\n\\t\\t\\t'label': capfirst(self.verbose_name),\\n\\t\\t\\t'required': not self.blank,\\n\\t\\t\\t'help_text': self.help_text\\n\\t\\t}\\n\\t\\tif self.has_default():\\n\\t\\t\\tif callable(self.default):\\n\\t\\t\\t\\tdefaults['initial'] = self.default\\n\\t\\t\\t\\tdefaults['show_hidden_initial'] = True\\n\\t\\t\\telse:\\n\\t\\t\\t\\tdefaults['initial'] = self.get_default()\", 'def validate(self, value, model_instance):\\n\\t\\tinvalid_values = []\\n\\t\\tfor val in value:\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tvalidate_slug(val)\\n\\t\\t\\texcept ValidationError:\\n\\t\\t\\t\\tinvalid_values.append(val)', \"def _get_choices(self):\\n\\t\\tif isinstance(self._choices, RegistryIterator):\\n\\t\\t\\treturn self._choices.copy()\\n\\t\\telif hasattr(self._choices, 'next'):\\n\\t\\t\\tchoices, self._choices = itertools.tee(self._choices)\\n\\t\\t\\treturn choices\\n\\t\\telse:\\n\\t\\t\\treturn self._choices\"]}, {'code': 'import hashlib\\nimport json\\nimport logging\\nimport os\\nimport subprocess\\nimport sys\\nimport time\\nfrom collections import defaultdict\\n\\nfrom shutil import copy\\nfrom shutil import copyfile\\nfrom shutil import copystat\\nfrom shutil import copytree\\nfrom tempfile import mkdtemp\\n\\nimport boto3\\nimport botocore\\nimport yaml\\nimport sys\\n\\nfrom .helpers import archive\\nfrom .helpers import get_environment_variable_value\\nfrom .helpers import LambdaContext\\nfrom .helpers import mkdir\\nfrom .helpers import read\\nfrom .helpers import timestamp\\n\\n\\nARN_PREFIXES = {\\n    \"cn-north-1\": \"aws-cn\",\\n    \"cn-northwest-1\": \"aws-cn\",\\n    \"us-gov-west-1\": \"aws-us-gov\",\\n}\\n\\nlog = logging.getLogger(__name__)\\n\\n\\ndef load_source(module_name, module_path):\\n    \"\"\"Loads a python module from the path of the corresponding file.\"\"\"\\n\\n    if sys.version_info[0] == 3 and sys.version_info[1] >= 5:\\n        import importlib.util\\n        spec = importlib.util.spec_from_file_location(module_name, module_path)\\n        module = importlib.util.module_from_spec(spec)\\n        spec.loader.exec_module(module)\\n    elif sys.version_info[0] == 3 and sys.version_info[1] < 5:\\n        import importlib.machinery\\n        loader = importlib.machinery.SourceFileLoader(module_name, module_path)\\n        module = loader.load_module()\\n    return module\\n\\n\\ndef cleanup_old_versions(\\n    src, keep_last_versions, config_file=\"config.yaml\", profile_name=None,\\n):\\n    \"\"\"Deletes old deployed versions of the function in AWS Lambda.\\n\\n    Won\\'t delete $Latest and any aliased version\\n\\n    :param str src:\\n        The path to your Lambda ready project (folder must contain a valid\\n        config.yaml and handler module (e.g.: service.py).\\n    :param int keep_last_versions:\\n        The number of recent versions to keep and not delete\\n    \"\"\"\\n    if keep_last_versions <= 0:\\n        print(\"Won\\'t delete all versions. Please do this manually\")\\n    else:\\n        path_to_config_file = os.path.join(src, config_file)\\n        cfg = read_cfg(path_to_config_file, profile_name)\\n\\n        profile_name = cfg.get(\"profile\")\\n        aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n        aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n\\n        client = get_client(\\n            \"lambda\",\\n            profile_name,\\n            aws_access_key_id,\\n            aws_secret_access_key,\\n            cfg.get(\"region\"),\\n        )\\n\\n        response = client.list_versions_by_function(\\n            FunctionName=cfg.get(\"function_name\"),\\n        )\\n        versions = response.get(\"Versions\")\\n        if len(response.get(\"Versions\")) < keep_last_versions:\\n            print(\"Nothing to delete. (Too few versions published)\")\\n        else:\\n            version_numbers = [\\n                elem.get(\"Version\") for elem in versions[1:-keep_last_versions]\\n            ]\\n            for version_number in version_numbers:\\n                try:\\n                    client.delete_function(\\n                        FunctionName=cfg.get(\"function_name\"),\\n                        Qualifier=version_number,\\n                    )\\n                except botocore.exceptions.ClientError as e:\\n                    print(f\"Skipping Version {version_number}: {e}\")\\n\\n\\ndef deploy(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n    preserve_vpc=False,\\n):\\n    \"\"\"Deploys a new function to AWS Lambda.\\n\\n    :param str src:\\n        The path to your Lambda ready project (folder must contain a valid\\n        config.yaml and handler module (e.g.: service.py).\\n    :param str local_package:\\n        The path to a local package with should be included in the deploy as\\n        well (and/or is not available on PyPi)\\n    \"\"\"\\n    # Load and parse the config file.\\n    path_to_config_file = os.path.join(src, config_file)\\n    cfg = read_cfg(path_to_config_file, profile_name)\\n\\n    # Copy all the pip dependencies required to run your code into a temporary\\n    # folder then add the handler file in the root of this directory.\\n    # Zip the contents of this folder into a single file and output to the dist\\n    # directory.\\n    path_to_zip_file = build(\\n        src,\\n        config_file=config_file,\\n        requirements=requirements,\\n        local_package=local_package,\\n    )\\n\\n    existing_config = get_function_config(cfg)\\n    if existing_config:\\n        update_function(\\n            cfg, path_to_zip_file, existing_config, preserve_vpc=preserve_vpc\\n        )\\n    else:\\n        create_function(cfg, path_to_zip_file)\\n\\n\\ndef deploy_s3(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n    preserve_vpc=False,\\n):\\n    \"\"\"Deploys a new function via AWS S3.\\n\\n    :param str src:\\n        The path to your Lambda ready project (folder must contain a valid\\n        config.yaml and handler module (e.g.: service.py).\\n    :param str local_package:\\n        The path to a local package with should be included in the deploy as\\n        well (and/or is not available on PyPi)\\n    \"\"\"\\n    # Load and parse the config file.\\n    path_to_config_file = os.path.join(src, config_file)\\n    cfg = read_cfg(path_to_config_file, profile_name)\\n\\n    # Copy all the pip dependencies required to run your code into a temporary\\n    # folder then add the handler file in the root of this directory.\\n    # Zip the contents of this folder into a single file and output to the dist\\n    # directory.\\n    path_to_zip_file = build(\\n        src,\\n        config_file=config_file,\\n        requirements=requirements,\\n        local_package=local_package,\\n    )\\n\\n    use_s3 = True\\n    s3_file = upload_s3(cfg, path_to_zip_file, use_s3)\\n    existing_config = get_function_config(cfg)\\n    if existing_config:\\n        update_function(\\n            cfg,\\n            path_to_zip_file,\\n            existing_config,\\n            use_s3=use_s3,\\n            s3_file=s3_file,\\n            preserve_vpc=preserve_vpc,\\n        )\\n    else:\\n        create_function(cfg, path_to_zip_file, use_s3=use_s3, s3_file=s3_file)\\n\\n\\ndef upload(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n):\\n    \"\"\"Uploads a new function to AWS S3.\\n\\n    :param str src:\\n        The path to your Lambda ready project (folder must contain a valid\\n        config.yaml and handler module (e.g.: service.py).\\n    :param str local_package:\\n        The path to a local package with should be included in the deploy as\\n        well (and/or is not available on PyPi)\\n    \"\"\"\\n    # Load and parse the config file.\\n    path_to_config_file = os.path.join(src, config_file)\\n    cfg = read_cfg(path_to_config_file, profile_name)\\n\\n    # Copy all the pip dependencies required to run your code into a temporary\\n    # folder then add the handler file in the root of this directory.\\n    # Zip the contents of this folder into a single file and output to the dist\\n    # directory.\\n    path_to_zip_file = build(\\n        src,\\n        config_file=config_file,\\n        requirements=requirements,\\n        local_package=local_package,\\n    )\\n\\n    upload_s3(cfg, path_to_zip_file)\\n\\n\\ndef invoke(\\n    src,\\n    event_file=\"event.json\",\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n    verbose=False,\\n):\\n    \"\"\"Simulates a call to your function.\\n\\n    :param str src:\\n        The path to your Lambda ready project (folder must contain a valid\\n        config.yaml and handler module (e.g.: service.py).\\n    :param str alt_event:\\n        An optional argument to override which event file to use.\\n    :param bool verbose:\\n        Whether to print out verbose details.\\n    \"\"\"\\n    # Load and parse the config file.\\n    path_to_config_file = os.path.join(src, config_file)\\n    cfg = read_cfg(path_to_config_file, profile_name)\\n\\n    # Set AWS_PROFILE environment variable based on `--profile` option.\\n    if profile_name:\\n        os.environ[\"AWS_PROFILE\"] = profile_name\\n\\n    # Load environment variables from the config file into the actual\\n    # environment.\\n    env_vars = cfg.get(\"environment_variables\")\\n    if env_vars:\\n        for key, value in env_vars.items():\\n            os.environ[key] = get_environment_variable_value(value)\\n\\n    # Load and parse event file.\\n    path_to_event_file = os.path.join(src, event_file)\\n    event = read(path_to_event_file, loader=json.loads)\\n\\n    # Tweak to allow module to import local modules\\n    try:\\n        sys.path.index(src)\\n    except ValueError:\\n        sys.path.append(src)\\n\\n    handler = cfg.get(\"handler\")\\n    # Inspect the handler string (<module>.<function name>) and translate it\\n    # into a function we can execute.\\n    fn = get_callable_handler_function(src, handler)\\n\\n    timeout = cfg.get(\"timeout\")\\n    if timeout:\\n        context = LambdaContext(cfg.get(\"function_name\"), timeout)\\n    else:\\n        context = LambdaContext(cfg.get(\"function_name\"))\\n\\n    start = time.time()\\n    results = fn(event, context)\\n    end = time.time()\\n\\n    print(\"{0}\".format(results))\\n    if verbose:\\n        print(\\n            \"\\\\nexecution time: {:.8f}s\\\\nfunction execution \"\\n            \"timeout: {:2}s\".format(end - start, cfg.get(\"timeout\", 15))\\n        )\\n\\n\\ndef init(src, minimal=False):\\n    \"\"\"Copies template files to a given directory.\\n\\n    :param str src:\\n        The path to output the template lambda project files.\\n    :param bool minimal:\\n        Minimal possible template files (excludes event.json).\\n    \"\"\"\\n\\n    templates_path = os.path.join(\\n        os.path.dirname(os.path.abspath(__file__)), \"project_templates\",\\n    )\\n    for filename in os.listdir(templates_path):\\n        if (minimal and filename == \"event.json\") or filename.endswith(\".pyc\"):\\n            continue\\n        dest_path = os.path.join(templates_path, filename)\\n\\n        if not os.path.isdir(dest_path):\\n            copy(dest_path, src)\\n\\n\\ndef build(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n):\\n    \"\"\"Builds the file bundle.\\n\\n    :param str src:\\n       The path to your Lambda ready project (folder must contain a valid\\n        config.yaml and handler module (e.g.: service.py).\\n    :param str local_package:\\n        The path to a local package with should be included in the deploy as\\n        well (and/or is not available on PyPi)\\n    \"\"\"\\n    # Load and parse the config file.\\n    path_to_config_file = os.path.join(src, config_file)\\n    cfg = read_cfg(path_to_config_file, profile_name)\\n\\n    # Get the absolute path to the output directory and create it if it doesn\\'t\\n    # already exist.\\n    dist_directory = cfg.get(\"dist_directory\", \"dist\")\\n    path_to_dist = os.path.join(src, dist_directory)\\n    mkdir(path_to_dist)\\n\\n    # Combine the name of the Lambda function with the current timestamp to use\\n    # for the output filename.\\n    function_name = cfg.get(\"function_name\")\\n    output_filename = \"{0}-{1}.zip\".format(timestamp(), function_name)\\n\\n    path_to_temp = mkdtemp(prefix=\"aws-lambda\")\\n    pip_install_to_target(\\n        path_to_temp, requirements=requirements, local_package=local_package,\\n    )\\n\\n    # Hack for Zope.\\n    if \"zope\" in os.listdir(path_to_temp):\\n        print(\\n            \"Zope packages detected; fixing Zope package paths to \"\\n            \"make them importable.\",\\n        )\\n        # Touch.\\n        with open(os.path.join(path_to_temp, \"zope/__init__.py\"), \"wb\"):\\n            pass\\n\\n    # Gracefully handle whether \".zip\" was included in the filename or not.\\n    output_filename = (\\n        \"{0}.zip\".format(output_filename)\\n        if not output_filename.endswith(\".zip\")\\n        else output_filename\\n    )\\n\\n    # Allow definition of source code directories we want to build into our\\n    # zipped package.\\n    build_config = defaultdict(**cfg.get(\"build\", {}))\\n    build_source_directories = build_config.get(\"source_directories\", \"\")\\n    build_source_directories = (\\n        build_source_directories\\n        if build_source_directories is not None\\n        else \"\"\\n    )\\n    source_directories = [\\n        d.strip() for d in build_source_directories.split(\",\")\\n    ]\\n\\n    files = []\\n    for filename in os.listdir(src):\\n        if os.path.isfile(filename):\\n            if filename == \".DS_Store\":\\n                continue\\n            if filename == config_file:\\n                continue\\n            print(\"Bundling: %r\" % filename)\\n            files.append(os.path.join(src, filename))\\n        elif os.path.isdir(filename) and filename in source_directories:\\n            print(\"Bundling directory: %r\" % filename)\\n            files.append(os.path.join(src, filename))\\n\\n    # \"cd\" into `temp_path` directory.\\n    os.chdir(path_to_temp)\\n    for f in files:\\n        if os.path.isfile(f):\\n            _, filename = os.path.split(f)\\n\\n            # Copy handler file into root of the packages folder.\\n            copyfile(f, os.path.join(path_to_temp, filename))\\n            copystat(f, os.path.join(path_to_temp, filename))\\n        elif os.path.isdir(f):\\n            src_path_length = len(src) + 1\\n            destination_folder = os.path.join(\\n                path_to_temp, f[src_path_length:]\\n            )\\n            copytree(f, destination_folder)\\n\\n    # Zip them together into a single file.\\n    # TODO: Delete temp directory created once the archive has been compiled.\\n    path_to_zip_file = archive(\"./\", path_to_dist, output_filename)\\n    return path_to_zip_file\\n\\n\\ndef get_callable_handler_function(src, handler):\\n    \"\"\"Translate a string of the form \"module.function\" into a callable\\n    function.\\n\\n    :param str src:\\n      The path to your Lambda project containing a valid handler file.\\n    :param str handler:\\n      A dot delimited string representing the `<module>.<function name>`.\\n    \"\"\"\\n\\n    # \"cd\" into `src` directory.\\n    os.chdir(src)\\n\\n    module_name, function_name = handler.split(\".\")\\n    filename = get_handler_filename(handler)\\n\\n    path_to_module_file = os.path.join(src, filename)\\n    module = load_source(module_name, path_to_module_file)\\n    return getattr(module, function_name)\\n\\n\\ndef get_handler_filename(handler):\\n    \"\"\"Shortcut to get the filename from the handler string.\\n\\n    :param str handler:\\n      A dot delimited string representing the `<module>.<function name>`.\\n    \"\"\"\\n    module_name, _ = handler.split(\".\")\\n    return \"{0}.py\".format(module_name)\\n\\n\\ndef _install_packages(path, packages):\\n    \"\"\"Install all packages listed to the target directory.\\n\\n    Ignores any package that includes Python itself and python-lambda as well\\n    since its only needed for deploying and not running the code\\n\\n    :param str path:\\n        Path to copy installed pip packages to.\\n    :param list packages:\\n        A list of packages to be installed via pip.\\n    \"\"\"\\n\\n    def _filter_blacklist(package):\\n        blacklist = [\"-i\", \"#\", \"Python==\", \"python-lambda==\"]\\n        return all(package.startswith(entry) is False for entry in blacklist)\\n\\n    filtered_packages = filter(_filter_blacklist, packages)\\n    for package in filtered_packages:\\n        if package.startswith(\"-e \"):\\n            package = package.replace(\"-e \", \"\")\\n\\n        print(\"Installing {package}\".format(package=package))\\n        subprocess.check_call(\\n            [\\n                sys.executable,\\n                \"-m\",\\n                \"pip\",\\n                \"install\",\\n                package,\\n                \"-t\",\\n                path,\\n                \"--ignore-installed\",\\n            ]\\n        )\\n    print(\\n        \"Install directory contents are now: {directory}\".format(\\n            directory=os.listdir(path)\\n        )\\n    )\\n\\n\\ndef pip_install_to_target(path, requirements=None, local_package=None):\\n    \"\"\"For a given active virtualenv, gather all installed pip packages then\\n    copy (re-install) them to the path provided.\\n\\n    :param str path:\\n        Path to copy installed pip packages to.\\n    :param str requirements:\\n        If set, only the packages in the supplied requirements file are\\n        installed.\\n        If not set then installs all packages found via pip freeze.\\n    :param str local_package:\\n        The path to a local package with should be included in the deploy as\\n        well (and/or is not available on PyPi)\\n    \"\"\"\\n    packages = []\\n    if not requirements:\\n        print(\"Gathering pip packages\")\\n        pkgStr = subprocess.check_output(\\n            [sys.executable, \"-m\", \"pip\", \"freeze\"]\\n        )\\n        packages.extend(pkgStr.decode(\"utf-8\").splitlines())\\n    else:\\n        if os.path.exists(requirements):\\n            print(\"Gathering requirement packages\")\\n            data = read(requirements)\\n            packages.extend(data.splitlines())\\n\\n    if not packages:\\n        print(\"No dependency packages installed!\")\\n\\n    if local_package is not None:\\n        if not isinstance(local_package, (list, tuple)):\\n            local_package = [local_package]\\n        for l_package in local_package:\\n            packages.append(l_package)\\n    _install_packages(path, packages)\\n\\n\\ndef get_role_name(region, account_id, role):\\n    \"\"\"Shortcut to insert the `account_id` and `role` into the iam string.\"\"\"\\n    prefix = ARN_PREFIXES.get(region, \"aws\")\\n    return \"arn:{0}:iam::{1}:role/{2}\".format(prefix, account_id, role)\\n\\n\\ndef get_account_id(\\n    profile_name, aws_access_key_id, aws_secret_access_key, region=None,\\n):\\n    \"\"\"Query STS for a users\\' account_id\"\"\"\\n    client = get_client(\\n        \"sts\", profile_name, aws_access_key_id, aws_secret_access_key, region,\\n    )\\n    return client.get_caller_identity().get(\"Account\")\\n\\n\\ndef get_client(\\n    client,\\n    profile_name,\\n    aws_access_key_id,\\n    aws_secret_access_key,\\n    region=None,\\n):\\n    \"\"\"Shortcut for getting an initialized instance of the boto3 client.\"\"\"\\n\\n    boto3.setup_default_session(\\n        profile_name=profile_name,\\n        aws_access_key_id=aws_access_key_id,\\n        aws_secret_access_key=aws_secret_access_key,\\n        region_name=region,\\n    )\\n    return boto3.client(client)\\n\\n\\ndef create_function(cfg, path_to_zip_file, use_s3=False, s3_file=None):\\n    \"\"\"Register and upload a function to AWS Lambda.\"\"\"\\n\\n    print(\"Creating your new Lambda function\")\\n    byte_stream = read(path_to_zip_file, binary_file=True)\\n    profile_name = cfg.get(\"profile\")\\n    aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n\\n    account_id = get_account_id(\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\",),\\n    )\\n    role = get_role_name(\\n        cfg.get(\"region\"),\\n        account_id,\\n        cfg.get(\"role\", \"lambda_basic_execution\"),\\n    )\\n\\n    client = get_client(\\n        \"lambda\",\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\"),\\n    )\\n\\n    # Do we prefer development variable over config?\\n    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\\n    func_name = os.environ.get(\"LAMBDA_FUNCTION_NAME\") or cfg.get(\\n        \"function_name\"\\n    )\\n    print(\"Creating lambda function with name: {}\".format(func_name))\\n\\n    if use_s3:\\n        kwargs = {\\n            \"FunctionName\": func_name,\\n            \"Runtime\": cfg.get(\"runtime\", \"python2.7\"),\\n            \"Role\": role,\\n            \"Handler\": cfg.get(\"handler\"),\\n            \"Code\": {\\n                \"S3Bucket\": \"{}\".format(buck_name),\\n                \"S3Key\": \"{}\".format(s3_file),\\n            },\\n            \"Description\": cfg.get(\"description\", \"\"),\\n            \"Timeout\": cfg.get(\"timeout\", 15),\\n            \"MemorySize\": cfg.get(\"memory_size\", 512),\\n            \"VpcConfig\": {\\n                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\\n                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\\n            },\\n            \"Publish\": True,\\n        }\\n    else:\\n        kwargs = {\\n            \"FunctionName\": func_name,\\n            \"Runtime\": cfg.get(\"runtime\", \"python2.7\"),\\n            \"Role\": role,\\n            \"Handler\": cfg.get(\"handler\"),\\n            \"Code\": {\"ZipFile\": byte_stream},\\n            \"Description\": cfg.get(\"description\", \"\"),\\n            \"Timeout\": cfg.get(\"timeout\", 15),\\n            \"MemorySize\": cfg.get(\"memory_size\", 512),\\n            \"VpcConfig\": {\\n                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\\n                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\\n            },\\n            \"Publish\": True,\\n        }\\n\\n    if \"tags\" in cfg:\\n        kwargs.update(\\n            Tags={key: str(value) for key, value in cfg.get(\"tags\").items()}\\n        )\\n\\n    if \"environment_variables\" in cfg:\\n        kwargs.update(\\n            Environment={\\n                \"Variables\": {\\n                    key: get_environment_variable_value(value)\\n                    for key, value in cfg.get(\"environment_variables\").items()\\n                },\\n            },\\n        )\\n\\n    client.create_function(**kwargs)\\n\\n    concurrency = get_concurrency(cfg)\\n    if concurrency > 0:\\n        client.put_function_concurrency(\\n            FunctionName=func_name, ReservedConcurrentExecutions=concurrency\\n        )\\n\\n\\ndef update_function(\\n    cfg,\\n    path_to_zip_file,\\n    existing_cfg,\\n    use_s3=False,\\n    s3_file=None,\\n    preserve_vpc=False,\\n):\\n    \"\"\"Updates the code of an existing Lambda function\"\"\"\\n\\n    print(\"Updating your Lambda function\")\\n    byte_stream = read(path_to_zip_file, binary_file=True)\\n    profile_name = cfg.get(\"profile\")\\n    aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n\\n    account_id = get_account_id(\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\",),\\n    )\\n    role = get_role_name(\\n        cfg.get(\"region\"),\\n        account_id,\\n        cfg.get(\"role\", \"lambda_basic_execution\"),\\n    )\\n\\n    client = get_client(\\n        \"lambda\",\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\"),\\n    )\\n\\n    # Do we prefer development variable over config?\\n    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\\n\\n    if use_s3:\\n        client.update_function_code(\\n            FunctionName=cfg.get(\"function_name\"),\\n            S3Bucket=\"{}\".format(buck_name),\\n            S3Key=\"{}\".format(s3_file),\\n            Publish=True,\\n        )\\n    else:\\n        client.update_function_code(\\n            FunctionName=cfg.get(\"function_name\"),\\n            ZipFile=byte_stream,\\n            Publish=True,\\n        )\\n\\n    kwargs = {\\n        \"FunctionName\": cfg.get(\"function_name\"),\\n        \"Role\": role,\\n        \"Runtime\": cfg.get(\"runtime\"),\\n        \"Handler\": cfg.get(\"handler\"),\\n        \"Description\": cfg.get(\"description\", \"\"),\\n        \"Timeout\": cfg.get(\"timeout\", 15),\\n        \"MemorySize\": cfg.get(\"memory_size\", 512),\\n    }\\n\\n    if preserve_vpc:\\n        kwargs[\"VpcConfig\"] = existing_cfg.get(\"Configuration\", {}).get(\\n            \"VpcConfig\"\\n        )\\n        if kwargs[\"VpcConfig\"] is None:\\n            kwargs[\"VpcConfig\"] = {\\n                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\\n                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\\n            }\\n        else:\\n            del kwargs[\"VpcConfig\"][\"VpcId\"]\\n    else:\\n        kwargs[\"VpcConfig\"] = {\\n            \"SubnetIds\": cfg.get(\"subnet_ids\", []),\\n            \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\\n        }\\n\\n    if \"environment_variables\" in cfg:\\n        kwargs.update(\\n            Environment={\\n                \"Variables\": {\\n                    key: str(get_environment_variable_value(value))\\n                    for key, value in cfg.get(\"environment_variables\").items()\\n                },\\n            },\\n        )\\n\\n    ret = client.update_function_configuration(**kwargs)\\n\\n    concurrency = get_concurrency(cfg)\\n    if concurrency > 0:\\n        client.put_function_concurrency(\\n            FunctionName=cfg.get(\"function_name\"),\\n            ReservedConcurrentExecutions=concurrency,\\n        )\\n    elif \"Concurrency\" in existing_cfg:\\n        client.delete_function_concurrency(\\n            FunctionName=cfg.get(\"function_name\")\\n        )\\n\\n    if \"tags\" in cfg:\\n        tags = {key: str(value) for key, value in cfg.get(\"tags\").items()}\\n        if tags != existing_cfg.get(\"Tags\"):\\n            if existing_cfg.get(\"Tags\"):\\n                client.untag_resource(\\n                    Resource=ret[\"FunctionArn\"],\\n                    TagKeys=list(existing_cfg[\"Tags\"].keys()),\\n                )\\n            client.tag_resource(Resource=ret[\"FunctionArn\"], Tags=tags)\\n\\n\\ndef upload_s3(cfg, path_to_zip_file, *use_s3):\\n    \"\"\"Upload a function to AWS S3.\"\"\"\\n\\n    print(\"Uploading your new Lambda function\")\\n    profile_name = cfg.get(\"profile\")\\n    aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n    client = get_client(\\n        \"s3\",\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\"),\\n    )\\n    byte_stream = b\"\"\\n    with open(path_to_zip_file, mode=\"rb\") as fh:\\n        byte_stream = fh.read()\\n    s3_key_prefix = cfg.get(\"s3_key_prefix\", \"/dist\")\\n    checksum = hashlib.new(\"md5\", byte_stream).hexdigest()\\n    timestamp = str(time.time())\\n    filename = \"{prefix}{checksum}-{ts}.zip\".format(\\n        prefix=s3_key_prefix, checksum=checksum, ts=timestamp,\\n    )\\n\\n    # Do we prefer development variable over config?\\n    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\\n    func_name = os.environ.get(\"LAMBDA_FUNCTION_NAME\") or cfg.get(\\n        \"function_name\"\\n    )\\n    kwargs = {\\n        \"Bucket\": \"{}\".format(buck_name),\\n        \"Key\": \"{}\".format(filename),\\n        \"Body\": byte_stream,\\n    }\\n\\n    client.put_object(**kwargs)\\n    print(\"Finished uploading {} to S3 bucket {}\".format(func_name, buck_name))\\n    if use_s3:\\n        return filename\\n\\n\\ndef get_function_config(cfg):\\n    \"\"\"Check whether a function exists or not and return its config\"\"\"\\n\\n    function_name = cfg.get(\"function_name\")\\n    profile_name = cfg.get(\"profile\")\\n    aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n    client = get_client(\\n        \"lambda\",\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\"),\\n    )\\n\\n    try:\\n        return client.get_function(FunctionName=function_name)\\n    except client.exceptions.ResourceNotFoundException as e:\\n        if \"Function not found\" in str(e):\\n            return False\\n\\n\\ndef get_concurrency(cfg):\\n    \"\"\"Return the Reserved Concurrent Executions if present in the config\"\"\"\\n    concurrency = int(cfg.get(\"concurrency\", 0))\\n    return max(0, concurrency)\\n\\n\\ndef read_cfg(path_to_config_file, profile_name):\\n    cfg = read(path_to_config_file, loader=yaml.full_load)\\n    if profile_name is not None:\\n        cfg[\"profile\"] = profile_name\\n    elif \"AWS_PROFILE\" in os.environ:\\n        cfg[\"profile\"] = os.environ[\"AWS_PROFILE\"]\\n    return cfg\\n', 'repo_name': 'nficano/python-lambda', 'path': 'aws_lambda/aws_lambda.py', 'language': 'Python', 'license': 'isc', 'size': 26779, 'reputation_features': {'num_stars': 1426, 'num_forks': 229, 'num_watchers': 1426, 'num_open_issues': 63, 'created_at': 1456485666.0}, 'functions': ['def load_source(module_name, module_path):\\n    \"\"\"Loads a python module from the path of the corresponding file.\"\"\"\\n\\n    if sys.version_info[0] == 3 and sys.version_info[1] >= 5:\\n        import importlib.util\\n        spec = importlib.util.spec_from_file_location(module_name, module_path)\\n        module = importlib.util.module_from_spec(spec)\\n        spec.loader.exec_module(module)\\n    elif sys.version_info[0] == 3 and sys.version_info[1] < 5:\\n        import importlib.machinery\\n        loader = importlib.machinery.SourceFileLoader(module_name, module_path)\\n        module = loader.load_module()\\n    return module', 'def deploy(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n    preserve_vpc=False,', 'def deploy_s3(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n    preserve_vpc=False,', 'def upload(\\n    src,\\n    requirements=None,\\n    local_package=None,\\n    config_file=\"config.yaml\",\\n    profile_name=None,', 'def invoke(\\n    src,\\n    event_file=\"event.json\",\\n    config_file=\"config.yaml\",\\n    profile_name=None,\\n    verbose=False,', 'def init(src, minimal=False):\\n    \"\"\"Copies template files to a given directory.\\n\\n    :param str src:\\n        The path to output the template lambda project files.\\n    :param bool minimal:\\n        Minimal possible template files (excludes event.json).\\n    \"\"\"\\n\\n    templates_path = os.path.join(\\n        os.path.dirname(os.path.abspath(__file__)), \"project_templates\",\\n    )\\n    for filename in os.listdir(templates_path):\\n        if (minimal and filename == \"event.json\") or filename.endswith(\".pyc\"):\\n            continue\\n        dest_path = os.path.join(templates_path, filename)\\n\\n        if not os.path.isdir(dest_path):\\n            copy(dest_path, src)', 'def get_callable_handler_function(src, handler):\\n    \"\"\"Translate a string of the form \"module.function\" into a callable\\n    function.\\n\\n    :param str src:\\n      The path to your Lambda project containing a valid handler file.\\n    :param str handler:\\n      A dot delimited string representing the `<module>.<function name>`.\\n    \"\"\"\\n\\n    # \"cd\" into `src` directory.\\n    os.chdir(src)\\n\\n    module_name, function_name = handler.split(\".\")\\n    filename = get_handler_filename(handler)\\n\\n    path_to_module_file = os.path.join(src, filename)\\n    module = load_source(module_name, path_to_module_file)\\n    return getattr(module, function_name)', 'def _install_packages(path, packages):\\n    \"\"\"Install all packages listed to the target directory.\\n\\n    Ignores any package that includes Python itself and python-lambda as well\\n    since its only needed for deploying and not running the code\\n\\n    :param str path:\\n        Path to copy installed pip packages to.\\n    :param list packages:\\n        A list of packages to be installed via pip.\\n    \"\"\"\\n\\n    def _filter_blacklist(package):\\n        blacklist = [\"-i\", \"#\", \"Python==\", \"python-lambda==\"]\\n        return all(package.startswith(entry) is False for entry in blacklist)\\n\\n    filtered_packages = filter(_filter_blacklist, packages)\\n    for package in filtered_packages:\\n        if package.startswith(\"-e \"):\\n            package = package.replace(\"-e \", \"\")\\n\\n        print(\"Installing {package}\".format(package=package))\\n        subprocess.check_call(\\n            [\\n                sys.executable,\\n                \"-m\",\\n                \"pip\",\\n                \"install\",\\n                package,\\n                \"-t\",\\n                path,\\n                \"--ignore-installed\",\\n            ]\\n        )\\n    print(\\n        \"Install directory contents are now: {directory}\".format(\\n            directory=os.listdir(path)\\n        )\\n    )', 'def get_role_name(region, account_id, role):\\n    \"\"\"Shortcut to insert the `account_id` and `role` into the iam string.\"\"\"\\n    prefix = ARN_PREFIXES.get(region, \"aws\")\\n    return \"arn:{0}:iam::{1}:role/{2}\".format(prefix, account_id, role)', 'def get_client(\\n    client,\\n    profile_name,\\n    aws_access_key_id,\\n    aws_secret_access_key,\\n    region=None,', 'def create_function(cfg, path_to_zip_file, use_s3=False, s3_file=None):\\n    \"\"\"Register and upload a function to AWS Lambda.\"\"\"\\n\\n    print(\"Creating your new Lambda function\")\\n    byte_stream = read(path_to_zip_file, binary_file=True)\\n    profile_name = cfg.get(\"profile\")\\n    aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n\\n    account_id = get_account_id(\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\",),\\n    )\\n    role = get_role_name(\\n        cfg.get(\"region\"),\\n        account_id,\\n        cfg.get(\"role\", \"lambda_basic_execution\"),\\n    )\\n\\n    client = get_client(\\n        \"lambda\",\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\"),\\n    )\\n\\n    # Do we prefer development variable over config?\\n    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\\n    func_name = os.environ.get(\"LAMBDA_FUNCTION_NAME\") or cfg.get(\\n        \"function_name\"\\n    )\\n    print(\"Creating lambda function with name: {}\".format(func_name))\\n\\n    if use_s3:\\n        kwargs = {\\n            \"FunctionName\": func_name,\\n            \"Runtime\": cfg.get(\"runtime\", \"python2.7\"),\\n            \"Role\": role,\\n            \"Handler\": cfg.get(\"handler\"),\\n            \"Code\": {\\n                \"S3Bucket\": \"{}\".format(buck_name),\\n                \"S3Key\": \"{}\".format(s3_file),\\n            },\\n            \"Description\": cfg.get(\"description\", \"\"),\\n            \"Timeout\": cfg.get(\"timeout\", 15),\\n            \"MemorySize\": cfg.get(\"memory_size\", 512),\\n            \"VpcConfig\": {\\n                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\\n                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\\n            },\\n            \"Publish\": True,\\n        }\\n    else:\\n        kwargs = {\\n            \"FunctionName\": func_name,\\n            \"Runtime\": cfg.get(\"runtime\", \"python2.7\"),\\n            \"Role\": role,\\n            \"Handler\": cfg.get(\"handler\"),\\n            \"Code\": {\"ZipFile\": byte_stream},\\n            \"Description\": cfg.get(\"description\", \"\"),\\n            \"Timeout\": cfg.get(\"timeout\", 15),\\n            \"MemorySize\": cfg.get(\"memory_size\", 512),\\n            \"VpcConfig\": {\\n                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\\n                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\\n            },\\n            \"Publish\": True,\\n        }\\n\\n    if \"tags\" in cfg:\\n        kwargs.update(\\n            Tags={key: str(value) for key, value in cfg.get(\"tags\").items()}\\n        )\\n\\n    if \"environment_variables\" in cfg:\\n        kwargs.update(\\n            Environment={\\n                \"Variables\": {\\n                    key: get_environment_variable_value(value)\\n                    for key, value in cfg.get(\"environment_variables\").items()\\n                },\\n            },\\n        )\\n\\n    client.create_function(**kwargs)\\n\\n    concurrency = get_concurrency(cfg)\\n    if concurrency > 0:\\n        client.put_function_concurrency(\\n            FunctionName=func_name, ReservedConcurrentExecutions=concurrency\\n        )', 'def upload_s3(cfg, path_to_zip_file, *use_s3):\\n    \"\"\"Upload a function to AWS S3.\"\"\"\\n\\n    print(\"Uploading your new Lambda function\")\\n    profile_name = cfg.get(\"profile\")\\n    aws_access_key_id = cfg.get(\"aws_access_key_id\")\\n    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\\n    client = get_client(\\n        \"s3\",\\n        profile_name,\\n        aws_access_key_id,\\n        aws_secret_access_key,\\n        cfg.get(\"region\"),\\n    )\\n    byte_stream = b\"\"\\n    with open(path_to_zip_file, mode=\"rb\") as fh:\\n        byte_stream = fh.read()\\n    s3_key_prefix = cfg.get(\"s3_key_prefix\", \"/dist\")\\n    checksum = hashlib.new(\"md5\", byte_stream).hexdigest()\\n    timestamp = str(time.time())\\n    filename = \"{prefix}{checksum}-{ts}.zip\".format(\\n        prefix=s3_key_prefix, checksum=checksum, ts=timestamp,\\n    )\\n\\n    # Do we prefer development variable over config?\\n    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\\n    func_name = os.environ.get(\"LAMBDA_FUNCTION_NAME\") or cfg.get(\\n        \"function_name\"\\n    )\\n    kwargs = {\\n        \"Bucket\": \"{}\".format(buck_name),\\n        \"Key\": \"{}\".format(filename),\\n        \"Body\": byte_stream,\\n    }\\n\\n    client.put_object(**kwargs)\\n    print(\"Finished uploading {} to S3 bucket {}\".format(func_name, buck_name))\\n    if use_s3:\\n        return filename', 'def get_concurrency(cfg):\\n    \"\"\"Return the Reserved Concurrent Executions if present in the config\"\"\"\\n    concurrency = int(cfg.get(\"concurrency\", 0))\\n    return max(0, concurrency)']}, {'code': '# Copyright (c) 2015, Max Fillinger <max@max-fillinger.net>\\n# \\n# Permission to use, copy, modify, and/or distribute this software for any\\n# purpose with or without fee is hereby granted, provided that the above\\n# copyright notice and this permission notice appear in all copies.\\n# \\n# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\\n# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\\n# AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\\n# INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\\n# LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\\n# OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\\n# PERFORMANCE OF THIS SOFTWARE.\\n\\n# The epub format specification is available at http://idpf.org/epub/201\\n\\n\\'\\'\\'Contains the EpubBuilder class to build epub2.0.1 files with the getebook\\nmodule.\\'\\'\\'\\n\\nimport html\\nimport re\\nimport datetime\\nimport getebook\\nimport os.path\\nimport re\\nimport zipfile\\n\\n__all__ = [\\'EpubBuilder\\', \\'EpubTOC\\', \\'Author\\']\\n\\ndef _normalize(name):\\n    \\'\\'\\'Transform \"Firstname [Middlenames] Lastname\" into\\n    \"Lastname, Firstname [Middlenames]\".\\'\\'\\'\\n    split = name.split()\\n    if len(split) == 1:\\n        return name\\n    return split[-1] + \\', \\' + \\' \\'.join(name[0:-1])\\n\\ndef _make_starttag(tag, attrs):\\n    \\'Write a starttag.\\'\\n    out = \\'<\\' + tag\\n    for key in attrs:\\n        out += \\' {}=\"{}\"\\'.format(key, html.escape(attrs[key]))\\n    out += \\'>\\'\\n    return out\\n\\ndef _make_xml_elem(tag, text, attr = []):\\n    \\'Write a flat xml element.\\'\\n    out = \\'    <\\' + tag\\n    for (key, val) in attr:\\n        out += \\' {}=\"{}\"\\'.format(key, val)\\n    if text:\\n        out += \\'>{}</{}>\\\\n\\'.format(text, tag)\\n    else:\\n        out += \\' />\\\\n\\'\\n    return out\\n\\nclass EpubTOC(getebook.TOC):\\n    \\'Table of contents.\\'\\n    _head = ((\\n      \\'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\\\n\\'\\n      \\'<ncx xmlns=\"http://www.daisy.org/z3986/2005/ncx/\" version=\"2005-1\" xml:lang=\"en-US\">\\\\n\\'\\n      \\'  <head>\\\\n\\'\\n      \\'    <meta name=\"dtb:uid\" content=\"{}\" />\\\\n\\'\\n      \\'    <meta name=\"dtb:depth\" content=\"{}\" />\\\\n\\'\\n      \\'    <meta name=\"dtb:totalPageCount\" content=\"0\" />\\\\n\\'\\n      \\'    <meta name=\"dtb:maxPageNumber\" content=\"0\" />\\\\n\\'\\n      \\'  </head>\\\\n\\'\\n      \\'  <docTitle>\\\\n\\'\\n      \\'    <text>{}</text>\\\\n\\'\\n      \\'  </docTitle>\\\\n\\'\\n    ))\\n    _doc_author = ((\\n      \\'  <docAuthor>\\\\n\\'\\n      \\'    <text>{}</text>\\\\n\\'\\n      \\'  </docAuthor>\\\\n\\'\\n    ))\\n    _navp = ((\\n      \\'{0}<navPoint id=\"nav{1}\">\\\\n\\'\\n      \\'{0}  <navLabel>\\\\n\\'\\n      \\'{0}    <text>{2}</text>\\\\n\\'\\n      \\'{0}  </navLabel>\\\\n\\'\\n      \\'{0}  <content src=\"{3}\" />\\\\n\\'\\n    ))\\n\\n    def _navp_xml(self, entry, indent_lvl):\\n        \\'Write xml for an entry and all its subentries.\\'\\n        xml = self._navp.format(\\'  \\'*indent_lvl, str(entry.no), entry.text,\\n          entry.target)\\n        for sub in entry.entries:\\n            xml += self._navp_xml(sub, indent_lvl+1)\\n        xml += \\'  \\'*indent_lvl + \\'</navPoint>\\\\n\\'\\n        return xml\\n\\n    def write_xml(self, uid, title, authors):\\n        \\'Write the xml code for the table of contents.\\'\\n        xml = self._head.format(uid, self.max_depth, title)\\n        for aut in authors:\\n            xml += self._doc_author.format(aut)\\n        xml += \\'  <navMap>\\\\n\\'\\n        for entry in self.entries:\\n            xml += self._navp_xml(entry, 2)\\n        xml += \\'  </navMap>\\\\n</ncx>\\'\\n        return xml\\n\\nclass _Fileinfo:\\n    \\'Information about a component file of an epub.\\'\\n    def __init__(self, name, in_spine = True, guide_title = None,\\n                 guide_type = None):\\n        \\'\\'\\'Initialize the object. If the file does not belong in the\\n        reading order, in_spine should be set to False. If it should\\n        appear in the guide, set guide_title and guide_type.\\'\\'\\'\\n        self.name = name\\n        (self.ident, ext) = os.path.splitext(name)\\n        name_split = name.rsplit(\\'.\\', 1)\\n        self.ident = name_split[0]\\n        self.in_spine = in_spine\\n        self.guide_title = guide_title\\n        self.guide_type = guide_type\\n        # Infer media-type from file extension\\n        ext = ext.lower()\\n        if ext in (\\'.htm\\', \\'.html\\', \\'.xhtml\\'):\\n            self.media_type = \\'application/xhtml+xml\\'\\n        elif ext in (\\'.png\\', \\'.gif\\', \\'.jpeg\\'):\\n            self.media_type = \\'image/\\' + ext\\n        elif ext == \\'.jpg\\':\\n            self.media_type = \\'image/jpeg\\'\\n        elif ext == \\'.css\\':\\n            self.media_type = \\'text/css\\'\\n        elif ext == \\'.ncx\\':\\n            self.media_type = \\'application/x-dtbncx+xml\\'\\n        else:\\n            raise ValueError(\\'Can\\\\\\'t infer media-type from extension: %s\\' % ext)\\n    def manifest_entry(self):\\n        \\'Write the XML element for the manifest.\\'\\n        return _make_xml_elem(\\'item\\', \\'\\',\\n          [\\n            (\\'href\\', self.name),\\n            (\\'id\\', self.ident),\\n            (\\'media-type\\', self.media_type)\\n          ])\\n    def spine_entry(self):\\n        \\'\\'\\'Write the XML element for the spine.\\n        (Empty string if in_spine is False.)\\'\\'\\'\\n        if self.in_spine:\\n            return _make_xml_elem(\\'itemref\\', \\'\\', [(\\'idref\\', self.ident)])\\n        else:\\n            return \\'\\'\\n    def guide_entry(self):\\n        \\'\\'\\'Write the XML element for the guide.\\n        (Empty string if no guide title and type are given.)\\'\\'\\'\\n        if self.guide_title and self.guide_type:\\n            return _make_xml_elem(\\'reference\\', \\'\\',\\n              [\\n                (\\'title\\', self.guide_title),\\n                (\\'type\\', self.guide_type),\\n                (\\'href\\', self.name)\\n              ])\\n        else:\\n            return \\'\\'\\n\\nclass _EpubMeta:\\n    \\'Metadata entry for an epub file.\\'\\n    def __init__(self, tag, text, *args):\\n        \\'\\'\\'The metadata entry is an XML element. *args is used for\\n        supplying the XML element\\'s attributes as (key, value) pairs.\\'\\'\\'\\n        self.tag = tag\\n        self.text = text\\n        self.attr = args\\n    def write_xml(self):\\n        \\'Write the XML element.\\'\\n        return _make_xml_elem(self.tag, self.text, self.attr)\\n    def __repr__(self):\\n        \\'Returns the text.\\'\\n        return self.text\\n    def __str__(self):\\n        \\'Returns the text.\\'\\n        return self.text\\n\\nclass _EpubDate(_EpubMeta):\\n    \\'Metadata element for the publication date.\\'\\n    _date_re = re.compile(\\'^([0-9]{4})(-[0-9]{2}(-[0-9]{2})?)?$\\')\\n    def __init__(self, date):\\n        \\'\\'\\'date must be a string of the form \"YYYY[-MM[-DD]]\". If it is\\n        not of this form, or if the date is invalid, ValueError is\\n        raised.\\'\\'\\'\\n        m = self._date_re.match(date) \\n        if not m:\\n            raise ValueError(\\'invalid date format\\')\\n        year = int(m.group(1))\\n        try:\\n            mon = int(m.group(2)[1:])\\n            if mon < 0 or mon > 12:\\n                raise ValueError(\\'month must be in 1..12\\')\\n        except IndexError:\\n            pass\\n        try:\\n            day = int(m.group(3)[1:])\\n            datetime.date(year, mon, day) # raises ValueError if invalid\\n        except IndexError:\\n            pass\\n        self.tag = \\'dc:date\\'\\n        self.text = date\\n        self.attr = ()\\n\\nclass _EpubLang(_EpubMeta):\\n    \\'Metadata element for the language of the book.\\'\\n    _lang_re = re.compile(\\'^[a-z]{2}(-[A-Z]{2})?$\\')\\n    def __init__(self, lang):\\n        \\'\\'\\'lang must be a lower-case two-letter language code,\\n        optionally followed by a \"-\" and a upper-case two-letter country\\n        code. (e.g., \"en\", \"en-US\", \"en-UK\", \"de\", \"de-DE\", \"de-AT\")\\'\\'\\'\\n        if self._lang_re.match(lang):\\n            self.tag = \\'dc:language\\'\\n            self.text = lang\\n            self.attr = ()\\n        else:\\n            raise ValueError(\\'invalid language format\\')\\n\\nclass Author(_EpubMeta):\\n    \\'\\'\\'To control the file-as and role attribute for the authors, pass\\n    an Author object to the EpubBuilder instead of a string. The file-as\\n    attribute is a form of the name used for sorting. The role attribute\\n    describes how the person was involved in the work.\\n\\n    You ONLY need this if an author\\'s name is not of the form\\n    \"Given-name Family-name\", or if you want to specify a role other\\n    than author. Otherwise, you can just pass a string.\\n\\n    The value of role should be a MARC relator, e.g., \"aut\" for author\\n    or \"edt\" for editor. See http://www.loc.gov/marc/relators/ for a\\n    full list.\\'\\'\\'\\n    def __init__(self, name, fileas = None, role = \\'aut\\'):\\n        \\'\\'\\'Initialize the object. If the argument \"fileas\" is not given,\\n        \"Last-name, First-name\" is used for the file-as attribute. If\\n        the argument \"role\" is not given, \"aut\" is used for the role\\n        attribute.\\'\\'\\'\\n        if not fileas:\\n            fileas = _normalize(name)\\n        self.tag = \\'dc:creator\\'\\n        self.text = name\\n        self.attr = ((\\'opf:file-as\\', fileas), (\\'opf:role\\', role))\\n\\nclass _OPFfile:\\n    \\'\\'\\'Class for writing the OPF (Open Packaging Format) file for an\\n    epub file. The OPF file contains the metadata, a manifest of all\\n    component files in the epub, a \"spine\" which specifies the reading\\n    order and a guide which points to important components of the book\\n    such as the title page.\\'\\'\\'\\n\\n    _opf = (\\n      \\'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\\\n\\'\\n      \\'<package version=\"2.0\" xmlns=\"http://www.idpf.org/2007/opf\" unique_identifier=\"uid_id\">\\\\n\\'\\n      \\'  <metadata xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:opf=\"http://www.idpf.org/2007/opf\">\\\\n\\'\\n      \\'{}\\'\\n      \\'  </metadata>\\\\n\\'\\n      \\'  <manifest>\\\\n\\'\\n      \\'{}\\'\\n      \\'  </manifest>\\\\n\\'\\n      \\'  <spine toc=\"toc\">\\\\n\\'\\n      \\'{}\\'\\n      \\'  </spine>\\\\n\\'\\n      \\'  <guide>\\\\n\\'\\n      \\'{}\\'\\n      \\'  </guide>\\\\n\\'\\n      \\'</package>\\\\n\\'\\n    )\\n    def __init__(self):\\n        \\'Initialize.\\'\\n        self.meta = []\\n        self.filelist = []\\n    def write_xml(self):\\n        \\'Write the XML code for the OPF file.\\'\\n        metadata = \\'\\'\\n        for elem in self.meta:\\n            metadata += elem.write_xml()\\n        manif = \\'\\'\\n        spine = \\'\\'\\n        guide = \\'\\'\\n        for finfo in self.filelist:\\n            manif += finfo.manifest_entry()\\n            spine += finfo.spine_entry()\\n            guide += finfo.guide_entry()\\n        return self._opf.format(metadata, manif, spine, guide)\\n\\nclass EpubBuilder:\\n    \\'\\'\\'Builds an epub2.0.1 file. Some of the attributes of this class\\n    (title, uid, lang) are marked as \"mandatory\" because they represent\\n    metadata that is required by the epub specification. If these\\n    attributes are left unset, default values will be used.\\'\\'\\'\\n\\n    _style_css = (\\n      \\'h1, h2, h3, h4, h5, h6 {\\\\n\\'\\n      \\'  text-align: center;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'p {\\\\n\\'\\n      \\'  text-align: justify;\\\\n\\'\\n      \\'  margin-top: 0.125em;\\\\n\\'\\n      \\'  margin-bottom: 0em;\\\\n\\'\\n      \\'  text-indent: 1.0em;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'.getebook-tp {\\\\n\\'\\n      \\'  margin-top: 8em;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'.getebook-tp-authors {\\\\n\\'\\n      \\'  font-size: 2em;\\\\n\\'\\n      \\'  text-align: center;\\\\n\\'\\n      \\'  margin-bottom: 1em;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'.getebook-tp-title {\\\\n\\'\\n      \\'  font-weight: bold;\\\\n\\'\\n      \\'  font-size: 3em;\\\\n\\'\\n      \\'  text-align: center;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'.getebook-tp-sub {\\\\n\\'\\n      \\'  text-align: center;\\\\n\\'\\n      \\'  font-weight: normal;\\\\n\\'\\n      \\'  font-size: 0.8em;\\\\n\\'\\n      \\'  margin-top: 1em;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'.getebook-false-h {\\\\n\\'\\n      \\'  font-weight: bold;\\\\n\\'\\n      \\'  font-size: 1.5em;\\\\n\\'\\n      \\'}\\\\n\\'\\n      \\'.getebook-small-h {\\\\n\\'\\n      \\'  font-style: normal;\\\\n\\'\\n      \\'  font-weight: normal;\\\\n\\'\\n      \\'  font-size: 0.8em;\\\\n\\'\\n      \\'}\\\\n\\'\\n    )\\n\\n    _container_xml = (\\n      \\'<?xml version=\"1.0\"?>\\\\n\\'\\n      \\'<container version=\"1.0\" xmlns=\"urn:oasis:names:tc:opendocument:xmlns:container\">\\\\n\\'\\n      \\'  <rootfiles>\\\\n\\'\\n      \\'    <rootfile full-path=\"package.opf\" media-type=\"application/oebps-package+xml\"/>\\\\n\\'\\n      \\'  </rootfiles>\\\\n\\'\\n      \\'</container>\\\\n\\'\\n    )\\n\\n    _html = (\\n      \\'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\\\n\\'\\n      \\'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//EN\" \"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd\">\\\\n\\'\\n      \\'<html xmlns=\"http://www.w3.org/1999/xhtml\">\\\\n\\'\\n      \\'  <head>\\\\n\\'\\n      \\'    <title>{}</title>\\\\n\\'\\n      \\'    <meta http-equiv=\"content-type\" content=\"application/xtml+xml; charset=utf-8\" />\\\\n\\'\\n      \\'    <link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\" />\\\\n\\'\\n      \\'  </head>\\\\n\\'\\n      \\'  <body>\\\\n{}\\'\\n      \\'  </body>\\\\n\\'\\n      \\'</html>\\\\n\\'\\n    )\\n\\n    _finalized = False\\n\\n    def __init__(self, epub_file):\\n        \\'\\'\\'Initialize the EpubBuilder instance. \"epub_file\" is the\\n        filename of the epub to be created.\\'\\'\\'\\n        self.epub_f = zipfile.ZipFile(epub_file, \\'w\\', zipfile.ZIP_DEFLATED)\\n        self.epub_f.writestr(\\'mimetype\\', \\'application/epub+zip\\')\\n        self.epub_f.writestr(\\'META-INF/container.xml\\', self._container_xml)\\n        self.toc = EpubTOC()\\n        self.opf = _OPFfile()\\n        self.opf.filelist.append(_Fileinfo(\\'toc.ncx\\', False))\\n        self.opf.filelist.append(_Fileinfo(\\'style.css\\', False))\\n        self._authors = []\\n        self.opt_meta = {} # Optional metadata (other than authors)\\n        self.content = \\'\\'\\n        self.part_no = 0\\n        self.cont_filename = \\'part%03d.html\\' % self.part_no\\n\\n    def __enter__(self):\\n        \\'Return self for use in with ... as ... statement.\\'\\n        return self\\n\\n    def __exit__(self, except_type, except_val, traceback):\\n        \\'Call finalize() and close the file.\\'\\n        try:\\n            self.finalize()\\n        finally:\\n            # Close again in case an exception happened in finalize()\\n            self.epub_f.close()\\n        return False\\n\\n    @property\\n    def uid(self):\\n        \\'\\'\\'Unique identifier of the ebook. (mandatory)\\n\\n        If this property is left unset, a pseudo-random string will be\\n        generated which is long enough for collisions with existing\\n        ebooks to be extremely unlikely.\\'\\'\\'\\n        try:\\n            return self._uid\\n        except AttributeError:\\n            import random\\n            from string import (ascii_letters, digits)\\n            alnum = ascii_letters + digits\\n            self.uid = \\'\\'.join([random.choice(alnum) for i in range(15)])\\n            return self._uid\\n    @uid.setter\\n    def uid(self, val):\\n        self._uid = _EpubMeta(\\'dc:identifier\\', str(val), (\\'id\\', \\'uid_id\\'))\\n\\n    @property\\n    def title(self):\\n        \\'\\'\\'Title of the ebook. (mandatory)\\n\\n        If this property is left unset, it defaults to \"Untitled\".\\'\\'\\'\\n        try:\\n            return self._title\\n        except AttributeError:\\n            self.title = \\'Untitled\\'\\n            return self._title\\n    @title.setter\\n    def title(self, val):\\n        # If val is not a string, raise TypeError now rather than later.\\n        self._title = _EpubMeta(\\'dc:title\\', \\'\\' + val)\\n\\n    @property\\n    def lang(self):\\n        \\'\\'\\'Language of the ebook. (mandatory)\\n\\n        The language must be given as a lower-case two-letter code, optionally\\n        followed by a \"-\" and an upper-case two-letter country code.\\n        (e.g., \"en\", \"en-US\", \"en-UK\", \"de\", \"de-DE\", \"de-AT\")\\n\\n        If this property is left unset, it defaults to \"en\".\\'\\'\\'\\n        try:\\n            return self._lang\\n        except AttributeError:\\n            self.lang = \\'en\\'\\n            return self._lang\\n    @lang.setter\\n    def lang(self, val):\\n        self._lang = _EpubLang(val)\\n\\n    @property\\n    def author(self):\\n        \\'\\'\\'Name of the author. (optional)\\n        \\n        If there are multiple authors, pass a list of strings.\\n\\n        To control the file-as and role attribute, use author objects instead\\n        of strings; file-as is an alternate form of the name used for sorting.\\n        For a description of the role attribute, see the docstring of the\\n        author class.\\'\\'\\'\\n        if len(self._authors) == 1:\\n            return self._authors[0]\\n        return tuple([aut for aut in self._authors])\\n    @author.setter\\n    def author(self, val):\\n        if isinstance(val, Author) or isinstance(val, str):\\n            authors = [val]\\n        else:\\n            authors = val\\n        for aut in authors:\\n            try:\\n                self._authors.append(Author(\\'\\' + aut))\\n            except TypeError:\\n                # aut is not a string, so it should be an Author object\\n                self._authors.append(aut)\\n    @author.deleter\\n    def author(self):\\n        self._authors = []\\n\\n    @property\\n    def date(self):\\n        \\'\\'\\'Publication date. (optional)\\n        \\n        Must be given in \"YYYY[-MM[-DD]]\" format.\\'\\'\\'\\n        try:\\n            return self.opt_meta[\\'date\\']\\n        except KeyError:\\n            return None\\n    @date.setter\\n    def date(self, val):\\n        self.opt_meta[\\'date\\'] = _EpubDate(val)\\n    @date.deleter\\n    def date(self):\\n        del self._date\\n\\n    @property\\n    def rights(self):\\n        \\'Copyright/licensing information. (optional)\\'\\n        try:\\n            return self.opt_meta[\\'rights\\']\\n        except KeyError:\\n            return None\\n    @rights.setter\\n    def rights(self, val):\\n        self.opt_meta[\\'rights\\'] = _EpubMeta(\\'dc:rights\\', \\'\\' + val)\\n    @rights.deleter\\n    def rights(self):\\n        del self._rights\\n\\n    @property\\n    def publisher(self):\\n        \\'Publisher name. (optional)\\'\\n        try:\\n            return self.opt_meta[\\'publisher\\']\\n        except KeyError:\\n            return None\\n    @publisher.setter\\n    def publisher(self, val):\\n        self.opt_meta[\\'publisher\\'] = _EpubMeta(\\'dc:publisher\\', \\'\\' + val)\\n    @publisher.deleter\\n    def publisher(self):\\n        del self._publisher\\n    \\n    @property\\n    def style_css(self):\\n        \\'\\'\\'CSS stylesheet for the files that are generated by the EpubBuilder\\n        instance. Can be overwritten or extended, but not deleted.\\'\\'\\'\\n        return self._style_css\\n    @style_css.setter\\n    def style_css(self, val):\\n        self._style_css = \\'\\' + val\\n\\n    def titlepage(self, main_title = None, subtitle = None):\\n        \\'\\'\\'Create a title page for the ebook. If no main_title is given,\\n        the title attribute of the EpubBuilder instance is used.\\'\\'\\'\\n        tp = \\'<div class=\"getebook-tp\">\\\\n\\'\\n        if len(self._authors) >= 1:\\n            if len(self._authors) == 1:\\n                aut_str = str(self._authors[0])\\n            else:\\n                aut_str = \\', \\'.join(str(self._authors[0:-1])) + \\', and \\' \\\\\\n                                                       + str(self._authors[-1])\\n            tp += \\'<div class=\"getebook-tp-authors\">%s</div>\\\\n\\' % aut_str\\n        if not main_title:\\n            main_title = str(self.title)\\n        tp += \\'<div class=\"getebook-tp-title\">%s\\' % main_title\\n        if subtitle:\\n            tp += \\'<div class=\"getebook-tp-sub\">%s</div>\\' % subtitle\\n        tp += \\'</div>\\\\n</div>\\\\n\\'\\n        self.opf.filelist.insert(0, _Fileinfo(\\'title.html\\',\\n          guide_title = \\'Titlepage\\', guide_type = \\'title-page\\'))\\n        self.epub_f.writestr(\\'title.html\\', self._html.format(self.title, tp))\\n\\n    def headingpage(self, heading, subtitle = None, toc_text = None):\\n        \\'\\'\\'Create a page containing only a (large) heading, optionally\\n        with a smaller subtitle. If toc_text is not given, it defaults\\n        to the heading.\\'\\'\\'\\n        self.new_part()\\n        tag = \\'h%d\\' % min(6, self.toc.depth)\\n        self.content += \\'<div class=\"getebook-tp\">\\'\\n        self.content += \\'<{} class=\"getebook-tp-title\">{}\\'.format(tag, heading)\\n        if subtitle:\\n            self.content += \\'<div class=\"getebook-tp-sub\">%s</div>\\' % subtitle\\n        self.content += \\'</%s>\\\\n\\' % tag\\n        if not toc_text:\\n            toc_text = heading\\n        self.toc.new_entry(toc_text, self.cont_filename)\\n        self.new_part()\\n\\n    def insert_file(self, name, in_spine = False, guide_title = None,\\n      guide_type = None, arcname = None):\\n        \\'\\'\\'Include an external file into the ebook. By default, it will\\n        be added to the archive under its basename; the argument\\n        \"arcname\" can be used to specify a different name.\\'\\'\\'\\n        if not arcname:\\n            arcname = os.path.basename(name)\\n        self.opf.filelist.append(_Fileinfo(arcname, in_spine, guide_title,\\n                                 guide_type))\\n        self.epub_f.write(name, arcname)\\n\\n    def add_file(self, arcname, str_or_bytes, in_spine = False,\\n      guide_title = None, guide_type = None):\\n        \\'\\'\\'Add the string or bytes instance str_or_bytes to the archive\\n        under the name arcname.\\'\\'\\'\\n        self.opf.filelist.append(_Fileinfo(arcname, in_spine, guide_title,\\n                                 guide_type))\\n        self.epub_f.writestr(arcname, str_or_bytes)\\n\\n    def false_heading(self, elem):\\n        \\'\\'\\'Handle a \"false heading\", i.e., text that appears in heading\\n        tags in the source even though it is not a chapter heading.\\'\\'\\'\\n        elem.attrs[\\'class\\'] = \\'getebook-false-h\\'\\n        elem.tag = \\'p\\'\\n        self.handle_elem(elem)\\n\\n    def _heading(self, elem):\\n        \\'\\'\\'Write a heading.\\'\\'\\'\\n        # Handle paragraph heading if we have one waiting (see the\\n        # par_heading method). We don\\\\\\'t use _handle_par_h here because\\n        # we merge it with the subsequent proper heading.\\n        try:\\n            par_h = self.par_h\\n            del self.par_h\\n        except AttributeError:\\n            toc_text = elem.text\\n        else:\\n            # There is a waiting paragraph heading, we merge it with the\\n            # new heading.\\n            toc_text = par_h.text + \\'. \\' + elem.text\\n            par_h.tag = \\'div\\'\\n            par_h.attrs[\\'class\\'] = \\'getebook-small-h\\'\\n            elem.children.insert(0, par_h)\\n        # Set the class attribute value.\\n        elem.attrs[\\'class\\'] = \\'getebook-chapter-h\\'\\n        self.toc.new_entry(toc_text, self.cont_filename)\\n        # Add heading to the epub.\\n        tag = \\'h%d\\' % min(self.toc.depth, 6)\\n        self.content += _make_starttag(tag, elem.attrs)\\n        for elem in elem.children:\\n            self.handle_elem(elem)\\n        self.content += \\'</%s>\\\\n\\' % tag\\n\\n    def par_heading(self, elem):\\n        \\'\\'\\'Handle a \"paragraph heading\", i.e., a chaper heading or part\\n        of a chapter heading inside paragraph tags. If it is immediately\\n        followed by a heading, they will be merged into one.\\'\\'\\'\\n        self.par_h = elem\\n\\n    def _handle_par_h(self):\\n        \\'Check if there is a waiting paragraph heading and handle it.\\'\\n        try:\\n            self._heading(self.par_h)\\n        except AttributeError:\\n            pass\\n\\n    def handle_elem(self, elem):\\n        \\'Handle html element as supplied by getebook.EbookParser.\\'\\n        try:\\n            tag = elem.tag\\n        except AttributeError:\\n            # elem should be a string\\n            is_string = True\\n            tag = None\\n        else:\\n            is_string = False\\n        if tag in getebook._headings:\\n            self._heading(elem)\\n        else:\\n            # Handle waiting par_h if necessary (see par_heading)\\n            try:\\n                self._heading(self.par_h)\\n            except AttributeError:\\n                pass\\n            if is_string:\\n                self.content += elem\\n            elif tag == \\'br\\':\\n                self.content += \\'<br />\\\\n\\'\\n            elif tag == \\'img\\':\\n                self.content += self._handle_image(elem.attrs) + \\'\\\\n\\'\\n            elif tag == \\'a\\' or tag == \\'noscript\\':\\n                # Ignore tag, just write child elements\\n                for child in elem.children:\\n                    self.handle_elem(child)\\n            else:\\n                self.content += _make_starttag(tag, elem.attrs)\\n                for child in elem.children:\\n                    self.handle_elem(child)\\n                self.content += \\'</%s>\\' % tag\\n                if tag == \\'p\\':\\n                    self.content += \\'\\\\n\\'\\n\\n    def _handle_image(self, attrs):\\n        \\'Returns the alt text of an image tag.\\'\\n        try:\\n            return attrs[\\'alt\\']\\n        except KeyError:\\n            return \\'\\'\\n\\n    def new_part(self):\\n        \\'\\'\\'Begin a new part of the epub. Write the current html document\\n        to the archive and begin a new one.\\'\\'\\'\\n        # Handle waiting par_h (see par_heading)\\n        try:\\n            self._heading(self.par_h)\\n        except AttributeError:\\n            pass\\n        if self.content:\\n            html = self._html.format(self.title, self.content)\\n            self.epub_f.writestr(self.cont_filename, html)\\n            self.part_no += 1\\n        self.content = \\'\\'\\n        self.cont_filename = \\'part%03d.html\\' % self.part_no\\n        self.opf.filelist.append(_Fileinfo(self.cont_filename))\\n\\n    def finalize(self):\\n        \\'Complete and close the epub file.\\'\\n        # Handle waiting par_h (see par_heading)\\n        if self._finalized:\\n            # Avoid finalizing twice. Otherwise, calling finalize inside\\n            # a with-block would lead to an exception when __exit__\\n            # calls finalize again.\\n            return\\n        try:\\n            self._heading(self.par_h)\\n        except AttributeError:\\n            pass\\n        if self.content:\\n            html = self._html.format(self.title, self.content)\\n            self.epub_f.writestr(self.cont_filename, html)\\n        self.opf.meta = [self.uid, self.lang, self.title] + self._authors\\n        self.opf.meta += self.opt_meta.values()\\n        self.epub_f.writestr(\\'package.opf\\', self.opf.write_xml())\\n        self.epub_f.writestr(\\'toc.ncx\\',\\n          self.toc.write_xml(self.uid, self.title, self._authors))\\n        self.epub_f.writestr(\\'style.css\\', self._style_css)\\n        self.epub_f.close()\\n        self._finalized = True\\n', 'repo_name': 'mfil/getebook', 'path': 'getebook/epub.py', 'language': 'Python', 'license': 'isc', 'size': 25314, 'reputation_features': {'num_stars': 0, 'num_forks': 0, 'num_watchers': 0, 'num_open_issues': 0, 'created_at': 1452584169.0}, 'functions': ['def _normalize(name):\\n    \\'\\'\\'Transform \"Firstname [Middlenames] Lastname\" into\\n    \"Lastname, Firstname [Middlenames]\".\\'\\'\\'\\n    split = name.split()\\n    if len(split) == 1:\\n        return name\\n    return split[-1] + \\', \\' + \\' \\'.join(name[0:-1])', 'def _make_xml_elem(tag, text, attr = []):\\n    \\'Write a flat xml element.\\'\\n    out = \\'    <\\' + tag\\n    for (key, val) in attr:\\n        out += \\' {}=\"{}\"\\'.format(key, val)\\n    if text:\\n        out += \\'>{}</{}>\\\\n\\'.format(text, tag)\\n    else:\\n        out += \\' />\\\\n\\'\\n    return out', \"def _navp_xml(self, entry, indent_lvl):\\n        'Write xml for an entry and all its subentries.'\\n        xml = self._navp.format('  '*indent_lvl, str(entry.no), entry.text,\\n          entry.target)\\n        for sub in entry.entries:\\n            xml += self._navp_xml(sub, indent_lvl+1)\\n        xml += '  '*indent_lvl + '</navPoint>\\\\n'\\n        return xml\", \"def __init__(self, name, in_spine = True, guide_title = None,\\n                 guide_type = None):\\n        '''Initialize the object. If the file does not belong in the\\n        reading order, in_spine should be set to False. If it should\\n        appear in the guide, set guide_title and guide_type.'''\\n        self.name = name\\n        (self.ident, ext) = os.path.splitext(name)\\n        name_split = name.rsplit('.', 1)\\n        self.ident = name_split[0]\\n        self.in_spine = in_spine\\n        self.guide_title = guide_title\\n        self.guide_type = guide_type\\n        # Infer media-type from file extension\\n        ext = ext.lower()\\n        if ext in ('.htm', '.html', '.xhtml'):\\n            self.media_type = 'application/xhtml+xml'\\n        elif ext in ('.png', '.gif', '.jpeg'):\\n            self.media_type = 'image/' + ext\\n        elif ext == '.jpg':\\n            self.media_type = 'image/jpeg'\\n        elif ext == '.css':\\n            self.media_type = 'text/css'\\n        elif ext == '.ncx':\\n            self.media_type = 'application/x-dtbncx+xml'\\n        else:\\n            raise ValueError('Can\\\\'t infer media-type from extension: %s' % ext)\", \"def spine_entry(self):\\n        '''Write the XML element for the spine.\\n        (Empty string if in_spine is False.)'''\\n        if self.in_spine:\\n            return _make_xml_elem('itemref', '', [('idref', self.ident)])\\n        else:\\n            return ''\", \"def __init__(self, tag, text, *args):\\n        '''The metadata entry is an XML element. *args is used for\\n        supplying the XML element's attributes as (key, value) pairs.'''\\n        self.tag = tag\\n        self.text = text\\n        self.attr = args\", \"def __repr__(self):\\n        'Returns the text.'\\n        return self.text\", 'def __init__(self, date):\\n        \\'\\'\\'date must be a string of the form \"YYYY[-MM[-DD]]\". If it is\\n        not of this form, or if the date is invalid, ValueError is\\n        raised.\\'\\'\\'\\n        m = self._date_re.match(date) \\n        if not m:\\n            raise ValueError(\\'invalid date format\\')\\n        year = int(m.group(1))\\n        try:\\n            mon = int(m.group(2)[1:])\\n            if mon < 0 or mon > 12:\\n                raise ValueError(\\'month must be in 1..12\\')\\n        except IndexError:\\n            pass\\n        try:\\n            day = int(m.group(3)[1:])\\n            datetime.date(year, mon, day) # raises ValueError if invalid\\n        except IndexError:\\n            pass\\n        self.tag = \\'dc:date\\'\\n        self.text = date\\n        self.attr = ()', 'def __init__(self, lang):\\n        \\'\\'\\'lang must be a lower-case two-letter language code,\\n        optionally followed by a \"-\" and a upper-case two-letter country\\n        code. (e.g., \"en\", \"en-US\", \"en-UK\", \"de\", \"de-DE\", \"de-AT\")\\'\\'\\'\\n        if self._lang_re.match(lang):\\n            self.tag = \\'dc:language\\'\\n            self.text = lang\\n            self.attr = ()\\n        else:\\n            raise ValueError(\\'invalid language format\\')', 'def __init__(self, name, fileas = None, role = \\'aut\\'):\\n        \\'\\'\\'Initialize the object. If the argument \"fileas\" is not given,\\n        \"Last-name, First-name\" is used for the file-as attribute. If\\n        the argument \"role\" is not given, \"aut\" is used for the role\\n        attribute.\\'\\'\\'\\n        if not fileas:\\n            fileas = _normalize(name)\\n        self.tag = \\'dc:creator\\'\\n        self.text = name\\n        self.attr = ((\\'opf:file-as\\', fileas), (\\'opf:role\\', role))', \"def __init__(self):\\n        'Initialize.'\\n        self.meta = []\\n        self.filelist = []\", 'def __init__(self, epub_file):\\n        \\'\\'\\'Initialize the EpubBuilder instance. \"epub_file\" is the\\n        filename of the epub to be created.\\'\\'\\'\\n        self.epub_f = zipfile.ZipFile(epub_file, \\'w\\', zipfile.ZIP_DEFLATED)\\n        self.epub_f.writestr(\\'mimetype\\', \\'application/epub+zip\\')\\n        self.epub_f.writestr(\\'META-INF/container.xml\\', self._container_xml)\\n        self.toc = EpubTOC()\\n        self.opf = _OPFfile()\\n        self.opf.filelist.append(_Fileinfo(\\'toc.ncx\\', False))\\n        self.opf.filelist.append(_Fileinfo(\\'style.css\\', False))\\n        self._authors = []\\n        self.opt_meta = {} # Optional metadata (other than authors)\\n        self.content = \\'\\'\\n        self.part_no = 0\\n        self.cont_filename = \\'part%03d.html\\' % self.part_no', \"def __exit__(self, except_type, except_val, traceback):\\n        'Call finalize() and close the file.'\\n        try:\\n            self.finalize()\\n        finally:\\n            # Close again in case an exception happened in finalize()\\n            self.epub_f.close()\\n        return False\", \"def uid(self):\\n        '''Unique identifier of the ebook. (mandatory)\\n\\n        If this property is left unset, a pseudo-random string will be\\n        generated which is long enough for collisions with existing\\n        ebooks to be extremely unlikely.'''\\n        try:\\n            return self._uid\\n        except AttributeError:\\n            import random\\n            from string import (ascii_letters, digits)\\n            alnum = ascii_letters + digits\\n            self.uid = ''.join([random.choice(alnum) for i in range(15)])\\n            return self._uid\", \"def uid(self, val):\\n        self._uid = _EpubMeta('dc:identifier', str(val), ('id', 'uid_id'))\", 'def title(self):\\n        \\'\\'\\'Title of the ebook. (mandatory)\\n\\n        If this property is left unset, it defaults to \"Untitled\".\\'\\'\\'\\n        try:\\n            return self._title\\n        except AttributeError:\\n            self.title = \\'Untitled\\'\\n            return self._title', \"def title(self, val):\\n        # If val is not a string, raise TypeError now rather than later.\\n        self._title = _EpubMeta('dc:title', '' + val)\", 'def lang(self):\\n        \\'\\'\\'Language of the ebook. (mandatory)\\n\\n        The language must be given as a lower-case two-letter code, optionally\\n        followed by a \"-\" and an upper-case two-letter country code.\\n        (e.g., \"en\", \"en-US\", \"en-UK\", \"de\", \"de-DE\", \"de-AT\")\\n\\n        If this property is left unset, it defaults to \"en\".\\'\\'\\'\\n        try:\\n            return self._lang\\n        except AttributeError:\\n            self.lang = \\'en\\'\\n            return self._lang', 'def lang(self, val):\\n        self._lang = _EpubLang(val)', \"def author(self):\\n        '''Name of the author. (optional)\", \"def author(self, val):\\n        if isinstance(val, Author) or isinstance(val, str):\\n            authors = [val]\\n        else:\\n            authors = val\\n        for aut in authors:\\n            try:\\n                self._authors.append(Author('' + aut))\\n            except TypeError:\\n                # aut is not a string, so it should be an Author object\\n                self._authors.append(aut)\", 'def author(self):\\n        self._authors = []', \"def date(self):\\n        '''Publication date. (optional)\", \"def date(self, val):\\n        self.opt_meta['date'] = _EpubDate(val)\", 'def date(self):\\n        del self._date', \"def rights(self):\\n        'Copyright/licensing information. (optional)'\\n        try:\\n            return self.opt_meta['rights']\\n        except KeyError:\\n            return None\", \"def rights(self, val):\\n        self.opt_meta['rights'] = _EpubMeta('dc:rights', '' + val)\", 'def rights(self):\\n        del self._rights', \"def publisher(self):\\n        'Publisher name. (optional)'\\n        try:\\n            return self.opt_meta['publisher']\\n        except KeyError:\\n            return None\", \"def publisher(self, val):\\n        self.opt_meta['publisher'] = _EpubMeta('dc:publisher', '' + val)\", 'def publisher(self):\\n        del self._publisher', \"def style_css(self):\\n        '''CSS stylesheet for the files that are generated by the EpubBuilder\\n        instance. Can be overwritten or extended, but not deleted.'''\\n        return self._style_css\", \"def style_css(self, val):\\n        self._style_css = '' + val\", 'def headingpage(self, heading, subtitle = None, toc_text = None):\\n        \\'\\'\\'Create a page containing only a (large) heading, optionally\\n        with a smaller subtitle. If toc_text is not given, it defaults\\n        to the heading.\\'\\'\\'\\n        self.new_part()\\n        tag = \\'h%d\\' % min(6, self.toc.depth)\\n        self.content += \\'<div class=\"getebook-tp\">\\'\\n        self.content += \\'<{} class=\"getebook-tp-title\">{}\\'.format(tag, heading)\\n        if subtitle:\\n            self.content += \\'<div class=\"getebook-tp-sub\">%s</div>\\' % subtitle\\n        self.content += \\'</%s>\\\\n\\' % tag\\n        if not toc_text:\\n            toc_text = heading\\n        self.toc.new_entry(toc_text, self.cont_filename)\\n        self.new_part()', \"def add_file(self, arcname, str_or_bytes, in_spine = False,\\n      guide_title = None, guide_type = None):\\n        '''Add the string or bytes instance str_or_bytes to the archive\\n        under the name arcname.'''\\n        self.opf.filelist.append(_Fileinfo(arcname, in_spine, guide_title,\\n                                 guide_type))\\n        self.epub_f.writestr(arcname, str_or_bytes)\", \"def _heading(self, elem):\\n        '''Write a heading.'''\\n        # Handle paragraph heading if we have one waiting (see the\\n        # par_heading method). We don\\\\'t use _handle_par_h here because\\n        # we merge it with the subsequent proper heading.\\n        try:\\n            par_h = self.par_h\\n            del self.par_h\\n        except AttributeError:\\n            toc_text = elem.text\\n        else:\\n            # There is a waiting paragraph heading, we merge it with the\\n            # new heading.\\n            toc_text = par_h.text + '. ' + elem.text\\n            par_h.tag = 'div'\\n            par_h.attrs['class'] = 'getebook-small-h'\\n            elem.children.insert(0, par_h)\\n        # Set the class attribute value.\\n        elem.attrs['class'] = 'getebook-chapter-h'\\n        self.toc.new_entry(toc_text, self.cont_filename)\\n        # Add heading to the epub.\\n        tag = 'h%d' % min(self.toc.depth, 6)\\n        self.content += _make_starttag(tag, elem.attrs)\\n        for elem in elem.children:\\n            self.handle_elem(elem)\\n        self.content += '</%s>\\\\n' % tag\", \"def _handle_par_h(self):\\n        'Check if there is a waiting paragraph heading and handle it.'\\n        try:\\n            self._heading(self.par_h)\\n        except AttributeError:\\n            pass\", \"def _handle_image(self, attrs):\\n        'Returns the alt text of an image tag.'\\n        try:\\n            return attrs['alt']\\n        except KeyError:\\n            return ''\"]}, {'code': 'import numpy as np\\nimport pandas as pd\\nfrom pandas import Series, DataFrame\\nfrom scipy.spatial import distance\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.cluster import DBSCAN\\nfrom sklearn import metrics\\nfrom sklearn.datasets.samples_generator import make_blobs\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn import decomposition  # PCA\\nfrom sklearn.metrics import confusion_matrix\\n\\nimport json\\n\\nimport ml.Features as ft\\nfrom utils import Utils\\n\\nclass Identifier(object):\\n\\n    def __init__(self):\\n        columns = [\\'mean_height\\', \\'min_height\\', \\'max_height\\', \\'mean_width\\', \\'min_width\\', \\'max_width\\', \\'time\\', \\'girth\\',\\'id\\']\\n        self.data = DataFrame(columns=columns)\\n        self.event = []\\n    @staticmethod\\n    def subscribe(ch, method, properties, body):\\n        \"\"\"\\n        prints the body message. It\\'s the default callback method\\n        :param ch: keep null\\n        :param method: keep null\\n        :param properties: keep null\\n        :param body: the message\\n        :return:\\n        \"\"\"\\n        #first we get the JSON from body\\n\\n        #we check if it\\'s part of the walking event\\n\\n        #if walking event is completed, we\\n\\n\\nif __name__ == \\'__main__\\':\\n    # we setup needed params\\n    MAX_HEIGHT = 203\\n    MAX_WIDTH = 142\\n    SPEED = 3\\n    SAMPLING_RATE = 8\\n    mq_host = \\'172.26.56.122\\'\\n    queue_name = \\'door_data\\'\\n    # setting up MQTT subscriber\\n    Utils.sub(queue_name=queue_name,callback=subscribe,host=mq_host)', 'repo_name': 'banacer/door-wiz', 'path': 'src/identification/Identifier.py', 'language': 'Python', 'license': 'mit', 'size': 1449, 'reputation_features': {'num_stars': 1, 'num_forks': 0, 'num_watchers': 1, 'num_open_issues': 0, 'created_at': 1462711750.0}, 'functions': [\"def __init__(self):\\n        columns = ['mean_height', 'min_height', 'max_height', 'mean_width', 'min_width', 'max_width', 'time', 'girth','id']\\n        self.data = DataFrame(columns=columns)\\n        self.event = []\", 'def subscribe(ch, method, properties, body):\\n        \"\"\"\\n        prints the body message. It\\'s the default callback method\\n        :param ch: keep null\\n        :param method: keep null\\n        :param properties: keep null\\n        :param body: the message\\n        :return:\\n        \"\"\"\\n        #first we get the JSON from body\\n\\n        #we check if it\\'s part of the walking event\\n\\n        #if walking event is completed, we']}]\n"
     ]
    }
   ],
   "source": [
    "dataset_heads = augmented_dataset.take(4)\n",
    "arr = list(dataset_heads)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nficano/python-lambda\n",
      "{'num_stars': 1426, 'num_forks': 229, 'num_watchers': 1426, 'num_open_issues': 63, 'created_at': 1456485666.0}\n",
      "def load_source(module_name, module_path):\n",
      "    \"\"\"Loads a python module from the path of the corresponding file.\"\"\"\n",
      "\n",
      "    if sys.version_info[0] == 3 and sys.version_info[1] >= 5:\n",
      "        import importlib.util\n",
      "        spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
      "        module = importlib.util.module_from_spec(spec)\n",
      "        spec.loader.exec_module(module)\n",
      "    elif sys.version_info[0] == 3 and sys.version_info[1] < 5:\n",
      "        import importlib.machinery\n",
      "        loader = importlib.machinery.SourceFileLoader(module_name, module_path)\n",
      "        module = loader.load_module()\n",
      "    return module\n",
      "def deploy(\n",
      "    src,\n",
      "    requirements=None,\n",
      "    local_package=None,\n",
      "    config_file=\"config.yaml\",\n",
      "    profile_name=None,\n",
      "    preserve_vpc=False,\n",
      "def deploy_s3(\n",
      "    src,\n",
      "    requirements=None,\n",
      "    local_package=None,\n",
      "    config_file=\"config.yaml\",\n",
      "    profile_name=None,\n",
      "    preserve_vpc=False,\n",
      "def upload(\n",
      "    src,\n",
      "    requirements=None,\n",
      "    local_package=None,\n",
      "    config_file=\"config.yaml\",\n",
      "    profile_name=None,\n",
      "def invoke(\n",
      "    src,\n",
      "    event_file=\"event.json\",\n",
      "    config_file=\"config.yaml\",\n",
      "    profile_name=None,\n",
      "    verbose=False,\n",
      "def init(src, minimal=False):\n",
      "    \"\"\"Copies template files to a given directory.\n",
      "\n",
      "    :param str src:\n",
      "        The path to output the template lambda project files.\n",
      "    :param bool minimal:\n",
      "        Minimal possible template files (excludes event.json).\n",
      "    \"\"\"\n",
      "\n",
      "    templates_path = os.path.join(\n",
      "        os.path.dirname(os.path.abspath(__file__)), \"project_templates\",\n",
      "    )\n",
      "    for filename in os.listdir(templates_path):\n",
      "        if (minimal and filename == \"event.json\") or filename.endswith(\".pyc\"):\n",
      "            continue\n",
      "        dest_path = os.path.join(templates_path, filename)\n",
      "\n",
      "        if not os.path.isdir(dest_path):\n",
      "            copy(dest_path, src)\n",
      "def get_callable_handler_function(src, handler):\n",
      "    \"\"\"Translate a string of the form \"module.function\" into a callable\n",
      "    function.\n",
      "\n",
      "    :param str src:\n",
      "      The path to your Lambda project containing a valid handler file.\n",
      "    :param str handler:\n",
      "      A dot delimited string representing the `<module>.<function name>`.\n",
      "    \"\"\"\n",
      "\n",
      "    # \"cd\" into `src` directory.\n",
      "    os.chdir(src)\n",
      "\n",
      "    module_name, function_name = handler.split(\".\")\n",
      "    filename = get_handler_filename(handler)\n",
      "\n",
      "    path_to_module_file = os.path.join(src, filename)\n",
      "    module = load_source(module_name, path_to_module_file)\n",
      "    return getattr(module, function_name)\n",
      "def _install_packages(path, packages):\n",
      "    \"\"\"Install all packages listed to the target directory.\n",
      "\n",
      "    Ignores any package that includes Python itself and python-lambda as well\n",
      "    since its only needed for deploying and not running the code\n",
      "\n",
      "    :param str path:\n",
      "        Path to copy installed pip packages to.\n",
      "    :param list packages:\n",
      "        A list of packages to be installed via pip.\n",
      "    \"\"\"\n",
      "\n",
      "    def _filter_blacklist(package):\n",
      "        blacklist = [\"-i\", \"#\", \"Python==\", \"python-lambda==\"]\n",
      "        return all(package.startswith(entry) is False for entry in blacklist)\n",
      "\n",
      "    filtered_packages = filter(_filter_blacklist, packages)\n",
      "    for package in filtered_packages:\n",
      "        if package.startswith(\"-e \"):\n",
      "            package = package.replace(\"-e \", \"\")\n",
      "\n",
      "        print(\"Installing {package}\".format(package=package))\n",
      "        subprocess.check_call(\n",
      "            [\n",
      "                sys.executable,\n",
      "                \"-m\",\n",
      "                \"pip\",\n",
      "                \"install\",\n",
      "                package,\n",
      "                \"-t\",\n",
      "                path,\n",
      "                \"--ignore-installed\",\n",
      "            ]\n",
      "        )\n",
      "    print(\n",
      "        \"Install directory contents are now: {directory}\".format(\n",
      "            directory=os.listdir(path)\n",
      "        )\n",
      "    )\n",
      "def get_role_name(region, account_id, role):\n",
      "    \"\"\"Shortcut to insert the `account_id` and `role` into the iam string.\"\"\"\n",
      "    prefix = ARN_PREFIXES.get(region, \"aws\")\n",
      "    return \"arn:{0}:iam::{1}:role/{2}\".format(prefix, account_id, role)\n",
      "def get_client(\n",
      "    client,\n",
      "    profile_name,\n",
      "    aws_access_key_id,\n",
      "    aws_secret_access_key,\n",
      "    region=None,\n",
      "def create_function(cfg, path_to_zip_file, use_s3=False, s3_file=None):\n",
      "    \"\"\"Register and upload a function to AWS Lambda.\"\"\"\n",
      "\n",
      "    print(\"Creating your new Lambda function\")\n",
      "    byte_stream = read(path_to_zip_file, binary_file=True)\n",
      "    profile_name = cfg.get(\"profile\")\n",
      "    aws_access_key_id = cfg.get(\"aws_access_key_id\")\n",
      "    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\n",
      "\n",
      "    account_id = get_account_id(\n",
      "        profile_name,\n",
      "        aws_access_key_id,\n",
      "        aws_secret_access_key,\n",
      "        cfg.get(\"region\",),\n",
      "    )\n",
      "    role = get_role_name(\n",
      "        cfg.get(\"region\"),\n",
      "        account_id,\n",
      "        cfg.get(\"role\", \"lambda_basic_execution\"),\n",
      "    )\n",
      "\n",
      "    client = get_client(\n",
      "        \"lambda\",\n",
      "        profile_name,\n",
      "        aws_access_key_id,\n",
      "        aws_secret_access_key,\n",
      "        cfg.get(\"region\"),\n",
      "    )\n",
      "\n",
      "    # Do we prefer development variable over config?\n",
      "    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\n",
      "    func_name = os.environ.get(\"LAMBDA_FUNCTION_NAME\") or cfg.get(\n",
      "        \"function_name\"\n",
      "    )\n",
      "    print(\"Creating lambda function with name: {}\".format(func_name))\n",
      "\n",
      "    if use_s3:\n",
      "        kwargs = {\n",
      "            \"FunctionName\": func_name,\n",
      "            \"Runtime\": cfg.get(\"runtime\", \"python2.7\"),\n",
      "            \"Role\": role,\n",
      "            \"Handler\": cfg.get(\"handler\"),\n",
      "            \"Code\": {\n",
      "                \"S3Bucket\": \"{}\".format(buck_name),\n",
      "                \"S3Key\": \"{}\".format(s3_file),\n",
      "            },\n",
      "            \"Description\": cfg.get(\"description\", \"\"),\n",
      "            \"Timeout\": cfg.get(\"timeout\", 15),\n",
      "            \"MemorySize\": cfg.get(\"memory_size\", 512),\n",
      "            \"VpcConfig\": {\n",
      "                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\n",
      "                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\n",
      "            },\n",
      "            \"Publish\": True,\n",
      "        }\n",
      "    else:\n",
      "        kwargs = {\n",
      "            \"FunctionName\": func_name,\n",
      "            \"Runtime\": cfg.get(\"runtime\", \"python2.7\"),\n",
      "            \"Role\": role,\n",
      "            \"Handler\": cfg.get(\"handler\"),\n",
      "            \"Code\": {\"ZipFile\": byte_stream},\n",
      "            \"Description\": cfg.get(\"description\", \"\"),\n",
      "            \"Timeout\": cfg.get(\"timeout\", 15),\n",
      "            \"MemorySize\": cfg.get(\"memory_size\", 512),\n",
      "            \"VpcConfig\": {\n",
      "                \"SubnetIds\": cfg.get(\"subnet_ids\", []),\n",
      "                \"SecurityGroupIds\": cfg.get(\"security_group_ids\", []),\n",
      "            },\n",
      "            \"Publish\": True,\n",
      "        }\n",
      "\n",
      "    if \"tags\" in cfg:\n",
      "        kwargs.update(\n",
      "            Tags={key: str(value) for key, value in cfg.get(\"tags\").items()}\n",
      "        )\n",
      "\n",
      "    if \"environment_variables\" in cfg:\n",
      "        kwargs.update(\n",
      "            Environment={\n",
      "                \"Variables\": {\n",
      "                    key: get_environment_variable_value(value)\n",
      "                    for key, value in cfg.get(\"environment_variables\").items()\n",
      "                },\n",
      "            },\n",
      "        )\n",
      "\n",
      "    client.create_function(**kwargs)\n",
      "\n",
      "    concurrency = get_concurrency(cfg)\n",
      "    if concurrency > 0:\n",
      "        client.put_function_concurrency(\n",
      "            FunctionName=func_name, ReservedConcurrentExecutions=concurrency\n",
      "        )\n",
      "def upload_s3(cfg, path_to_zip_file, *use_s3):\n",
      "    \"\"\"Upload a function to AWS S3.\"\"\"\n",
      "\n",
      "    print(\"Uploading your new Lambda function\")\n",
      "    profile_name = cfg.get(\"profile\")\n",
      "    aws_access_key_id = cfg.get(\"aws_access_key_id\")\n",
      "    aws_secret_access_key = cfg.get(\"aws_secret_access_key\")\n",
      "    client = get_client(\n",
      "        \"s3\",\n",
      "        profile_name,\n",
      "        aws_access_key_id,\n",
      "        aws_secret_access_key,\n",
      "        cfg.get(\"region\"),\n",
      "    )\n",
      "    byte_stream = b\"\"\n",
      "    with open(path_to_zip_file, mode=\"rb\") as fh:\n",
      "        byte_stream = fh.read()\n",
      "    s3_key_prefix = cfg.get(\"s3_key_prefix\", \"/dist\")\n",
      "    checksum = hashlib.new(\"md5\", byte_stream).hexdigest()\n",
      "    timestamp = str(time.time())\n",
      "    filename = \"{prefix}{checksum}-{ts}.zip\".format(\n",
      "        prefix=s3_key_prefix, checksum=checksum, ts=timestamp,\n",
      "    )\n",
      "\n",
      "    # Do we prefer development variable over config?\n",
      "    buck_name = os.environ.get(\"S3_BUCKET_NAME\") or cfg.get(\"bucket_name\")\n",
      "    func_name = os.environ.get(\"LAMBDA_FUNCTION_NAME\") or cfg.get(\n",
      "        \"function_name\"\n",
      "    )\n",
      "    kwargs = {\n",
      "        \"Bucket\": \"{}\".format(buck_name),\n",
      "        \"Key\": \"{}\".format(filename),\n",
      "        \"Body\": byte_stream,\n",
      "    }\n",
      "\n",
      "    client.put_object(**kwargs)\n",
      "    print(\"Finished uploading {} to S3 bucket {}\".format(func_name, buck_name))\n",
      "    if use_s3:\n",
      "        return filename\n",
      "def get_concurrency(cfg):\n",
      "    \"\"\"Return the Reserved Concurrent Executions if present in the config\"\"\"\n",
      "    concurrency = int(cfg.get(\"concurrency\", 0))\n",
      "    return max(0, concurrency)\n"
     ]
    }
   ],
   "source": [
    "print(arr[1][\"repo_name\"])\n",
    "print(arr[1][\"reputation_features\"])\n",
    "print(\"\\n\".join(arr[1][\"functions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "224n_final_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc55353a1bb80ecd70b1e2768f9d432cf9eb903a27b85be7b0971feae070db5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
